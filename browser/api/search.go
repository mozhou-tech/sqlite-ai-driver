package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/sirupsen/logrus"
)

// fulltextSearch å…¨æ–‡æœç´¢
func fulltextSearch(c *gin.Context) {
	name := c.Param("name")

	var req FulltextSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	start := time.Now()

	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true
	}

	if !hasContent {
		logrus.Warn("Content column does not exist, using data column for search")
		query := `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND data LIKE ?
		LIMIT ?
		`
		searchPattern := "%" + req.Query + "%"
		rows, err := sqlDB.Query(query, name, searchPattern, req.Limit)
		if err != nil {
			logrus.WithError(err).Error("Fulltext search failed")
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
			return
		}
		defer rows.Close()

		var results []gin.H
		for rows.Next() {
			var docID, collectionName, dataJSON string
			var score float64
			if err := rows.Scan(&docID, &collectionName, &dataJSON, &score); err != nil {
				logrus.WithError(err).Error("Failed to scan row")
				continue
			}

			if req.Threshold > 0 && score < req.Threshold {
				continue
			}

			var data map[string]interface{}
			if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
				logrus.WithError(err).Warn("Failed to unmarshal document data")
				continue
			}

			results = append(results, gin.H{
				"document": DocumentResponse{
					ID:   docID,
					Data: data,
				},
				"score": score,
			})
		}

		took := time.Since(start).Milliseconds()
		c.JSON(http.StatusOK, gin.H{
			"results": results,
			"query":   req.Query,
			"took":    took,
		})
		return
	}

	var indexExists bool
	checkSQL := `SELECT COUNT(*) FROM pragma_table_info('documents') WHERE name = 'content'`
	var count int
	if err := sqlDB.QueryRow(checkSQL).Scan(&count); err == nil && count > 0 {
		indexExists = false
	}

	if !indexExists {
		logrus.Warn("FTS index does not exist, attempting to create it")
		if err := createDuckDBFTSIndex(sqlDB); err != nil {
			logrus.WithError(err).Error("Failed to create FTS index")
		}
	}

	queryTokens := tokenizeWithSego(req.Query)

	hasContentTokens, err := columnExists(sqlDB, "documents", "content_tokens")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content_tokens column, assuming it exists")
		hasContentTokens = true
	}

	var query string
	var searchText string
	if hasContentTokens && queryTokens != "" {
		query = `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND content_tokens MATCH ?
		LIMIT ?
		`
		searchText = queryTokens
	} else {
		query = `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND content MATCH ?
		LIMIT ?
		`
		searchText = req.Query
	}

	rows, err := sqlDB.Query(query, name, searchText, req.Limit)
	if err != nil {
		logrus.WithError(err).Warn("FTS query failed, using LIKE query as fallback")
		if hasContentTokens && queryTokens != "" {
			query = `
			SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
			FROM documents
			WHERE collection_name = ? 
			  AND content_tokens LIKE ?
			LIMIT ?
			`
			searchPattern := "%" + queryTokens + "%"
			rows, err = sqlDB.Query(query, name, searchPattern, req.Limit)
		} else {
			query = `
			SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
			FROM documents
			WHERE collection_name = ? 
			  AND content LIKE ?
			LIMIT ?
			`
			searchPattern := "%" + req.Query + "%"
			rows, err = sqlDB.Query(query, name, searchPattern, req.Limit)
		}
		if err != nil {
			logrus.WithError(err).Error("Fulltext search failed")
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
			return
		}
	}
	defer rows.Close()

	var results []gin.H
	for rows.Next() {
		var docID, collectionName, dataJSON string
		var score float64
		if err := rows.Scan(&docID, &collectionName, &dataJSON, &score); err != nil {
			logrus.WithError(err).Error("Failed to scan row")
			continue
		}

		if req.Threshold > 0 && score < req.Threshold {
			continue
		}

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			continue
		}

		results = append(results, gin.H{
			"document": DocumentResponse{
				ID:   docID,
				Data: data,
			},
			"score": score,
		})
	}

	took := time.Since(start).Milliseconds()
	c.JSON(http.StatusOK, gin.H{
		"results": results,
		"query":   req.Query,
		"took":    took,
	})
}

// vectorSearch å‘é‡æœç´¢
func vectorSearch(c *gin.Context) {
	name := c.Param("name")

	bodyBytes, _ := io.ReadAll(c.Request.Body)
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	var req VectorSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		logrus.WithError(err).Error("Failed to bind JSON")
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: fmt.Sprintf("Invalid request format: %v", err),
		})
		return
	}

	logrus.WithFields(logrus.Fields{
		"collection":   name,
		"hasQuery":     len(req.Query) > 0,
		"hasQueryText": req.QueryText != "",
		"queryText":    req.QueryText,
		"limit":        req.Limit,
		"field":        req.Field,
	}).Info("Vector search request")

	var queryVector []float64
	if req.QueryText != "" {
		logrus.WithField("queryText", req.QueryText).Info("ğŸ”„ Generating embedding from text")
		embedding, err := generateEmbeddingFromText(req.QueryText)
		if err != nil {
			logrus.WithError(err).Error("âŒ Failed to generate embedding from text")
			c.JSON(http.StatusBadRequest, ErrorResponse{
				Error: fmt.Sprintf("Failed to generate embedding from text: %v", err),
			})
			return
		}
		queryVector = embedding
		logrus.WithFields(logrus.Fields{
			"dimension": len(queryVector),
			"first3":    queryVector[:min(3, len(queryVector))],
		}).Info("âœ… Generated embedding")
	} else if len(req.Query) > 0 {
		queryVector = req.Query
		logrus.WithField("dimension", len(queryVector)).Info("Using provided vector")
	} else {
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: "Either 'query' (vector) or 'query_text' (text) must be provided",
		})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	if req.Field == "" {
		req.Field = "embedding"
	}

	// ä½¿ç”¨æ•°æ®åº“å‘é‡æœç´¢ï¼Œå¤±è´¥åˆ™ç›´æ¥æŠ¥é”™
	vectorSearchDB(c, name, req, queryVector)
}

// vectorSearchDB ä½¿ç”¨æ•°æ®åº“è¿›è¡Œå‘é‡æœç´¢
func vectorSearchDB(c *gin.Context, name string, req VectorSearchRequest, queryVector []float64) {
	start := time.Now()

	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(sqlDB, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Error("Failed to check embedding column")
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: fmt.Sprintf("Failed to check embedding column: %v", err),
		})
		return
	}

	if !hasEmbedding {
		logrus.Error("embedding column does not exist")
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "å‘é‡æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šembedding åˆ—ä¸å­˜åœ¨ã€‚è¯·ç¡®ä¿å·²æ­£ç¡®åˆ›å»ºå‘é‡ç´¢å¼•ã€‚",
		})
		return
	}

	// å°†æŸ¥è¯¢å‘é‡è½¬æ¢ä¸º DuckDB å¯ä»¥æ¥å—çš„æ ¼å¼
	// DuckDB éœ€è¦ FLOAT[] ç±»å‹
	vectorStr := "["
	for i, v := range queryVector {
		if i > 0 {
			vectorStr += ", "
		}
		vectorStr += fmt.Sprintf("%g", v)
	}
	vectorStr += "]"

	// ä½¿ç”¨ DuckDB çš„ list_cosine_similarity è¿›è¡Œå‘é‡æœç´¢
	// list_cosine_similarity è¿”å›è·ç¦»ï¼ˆdistanceï¼‰ï¼Œè·ç¦»è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜
	// ç›¸ä¼¼åº¦ = 1 - è·ç¦»ï¼Œæ‰€ä»¥æŒ‰è·ç¦»å‡åºæ’åˆ—ï¼ˆç›¸ä¼¼åº¦é™åºï¼‰
	query := `
		SELECT 
			id,
			collection_name,
			data,
			1 - list_cosine_similarity(embedding, ?::FLOAT[]) as similarity
		FROM documents
		WHERE collection_name = ? 
		  AND embedding IS NOT NULL
		ORDER BY list_cosine_similarity(embedding, ?::FLOAT[]) ASC
		LIMIT ?
	`

	rows, err := sqlDB.Query(query, vectorStr, name, vectorStr, req.Limit*2) // è·å–æ›´å¤šç»“æœä»¥ä¾¿è¿‡æ»¤
	if err != nil {
		logrus.WithError(err).Error("Vector search query failed")
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: fmt.Sprintf("å‘é‡æœç´¢å¤±è´¥: %v", err),
		})
		return
	}
	defer rows.Close()

	var results []gin.H
	for rows.Next() {
		var docID, collectionName, dataJSON string
		var similarity float64
		if err := rows.Scan(&docID, &collectionName, &dataJSON, &similarity); err != nil {
			logrus.WithError(err).Error("Failed to scan row")
			continue
		}

		// åº”ç”¨é˜ˆå€¼è¿‡æ»¤
		if req.Threshold > 0 && similarity < req.Threshold {
			continue
		}

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			continue
		}

		results = append(results, gin.H{
			"document": DocumentResponse{
				ID:   docID,
				Data: data,
			},
			"score": similarity,
		})

		// è¾¾åˆ°é™åˆ¶æ•°é‡ååœæ­¢
		if len(results) >= req.Limit {
			break
		}
	}

	if err := rows.Err(); err != nil {
		logrus.WithError(err).Error("Error iterating rows")
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: fmt.Sprintf("å‘é‡æœç´¢å¤„ç†å¤±è´¥: %v", err),
		})
		return
	}

	took := time.Since(start).Milliseconds()

	c.JSON(http.StatusOK, gin.H{
		"results": results,
		"query":   req.QueryText,
		"took":    took,
	})
}

// cosineSimilarity è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
func cosineSimilarity(a, b []float64) float64 {
	if len(a) != len(b) {
		return 0.0
	}

	var dotProduct, normA, normB float64
	for i := 0; i < len(a); i++ {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0.0
	}

	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}
