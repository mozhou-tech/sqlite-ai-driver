package main

import (
	"bytes"
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"net/http"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"github.com/gin-contrib/cors"
	"github.com/gin-gonic/gin"
	cayley_driver "github.com/mozhou-tech/sqlite-ai-driver/pkg/cayley-driver"
	_ "github.com/mozhou-tech/sqlite-ai-driver/pkg/duckdb-driver"
	_ "github.com/mozhou-tech/sqlite-ai-driver/pkg/sqlite3-driver"
	"github.com/sirupsen/logrus"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"
)

var (
	gormDB    *gorm.DB
	sqlDB     *sql.DB
	graphDB   cayley_driver.Graph
	dbContext context.Context
)

// Document æ–‡æ¡£æ¨¡å‹
type Document struct {
	ID             string    `gorm:"primaryKey;type:varchar(255);not null"`
	CollectionName string    `gorm:"type:varchar(255);not null;index"`
	Data           string    `gorm:"type:text"`     // JSON æ ¼å¼å­˜å‚¨
	Embedding      string    `gorm:"type:DOUBLE[]"` // å‘é‡æ•°æ®ï¼Œå­˜å‚¨ä¸ºæ•°ç»„
	Content        string    `gorm:"type:text"`     // æå–çš„æ–‡æœ¬å†…å®¹ï¼Œç”¨äºå…¨æ–‡æœç´¢
	CreatedAt      time.Time `gorm:"autoCreateTime"`
	UpdatedAt      time.Time `gorm:"autoUpdateTime"`
}

// TableName æŒ‡å®šè¡¨å
func (Document) TableName() string {
	return "documents"
}

// DatabaseConfig æ•°æ®åº“é…ç½®
type DatabaseConfig struct {
	Name string `json:"name"`
	Path string `json:"path"`
}

// CollectionInfo é›†åˆä¿¡æ¯
type CollectionInfo struct {
	Name   string                 `json:"name"`
	Schema map[string]interface{} `json:"schema"`
}

// DocumentResponse æ–‡æ¡£å“åº”
type DocumentResponse struct {
	ID   string                 `json:"id"`
	Data map[string]interface{} `json:"data"`
}

// FulltextSearchRequest å…¨æ–‡æœç´¢è¯·æ±‚
type FulltextSearchRequest struct {
	Collection string  `json:"collection"`
	Query      string  `json:"query"`
	Limit      int     `json:"limit"`
	Threshold  float64 `json:"threshold"`
}

// VectorSearchRequest å‘é‡æœç´¢è¯·æ±‚
type VectorSearchRequest struct {
	Collection string    `json:"collection,omitempty"`
	Query      []float64 `json:"query,omitempty"`
	QueryText  string    `json:"query_text,omitempty"`
	Limit      int       `json:"limit,omitempty"`
	Field      string    `json:"field,omitempty"`
	Threshold  float64   `json:"threshold,omitempty"`
}

// ErrorResponse é”™è¯¯å“åº”
type ErrorResponse struct {
	Error string `json:"error"`
}

func main() {
	// ä»ç¯å¢ƒå˜é‡è¯»å–æ•°æ®åº“é…ç½®
	dbName := os.Getenv("DB_NAME")
	if dbName == "" {
		dbName = "browser-db"
	}

	dbPath := os.Getenv("DB_PATH")
	if dbPath == "" {
		dbPath = "./data/browser-db"
	}

	// ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(dbPath, 0755); err != nil {
		logrus.WithError(err).Fatal("Failed to create data directory")
	}

	ctx := context.Background()
	dbContext = ctx

	// åˆå§‹åŒ– DuckDB æ•°æ®åº“
	// DuckDB éœ€è¦æ–‡ä»¶è·¯å¾„ï¼Œè€Œä¸æ˜¯ç›®å½•è·¯å¾„
	duckDBPath := filepath.Join(dbPath, "browser.db")
	// è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œé¿å…å·¥ä½œç›®å½•é—®é¢˜
	absDBPath, err := filepath.Abs(duckDBPath)
	if err != nil {
		logrus.WithError(err).Fatal("Failed to get absolute path")
	}
	logrus.WithField("db_path", absDBPath).Info("Database path")

	// ç›´æ¥ä½¿ç”¨ database/sql è¿æ¥ DuckDB
	sqlDB, err = sql.Open("duckdb", absDBPath)
	if err != nil {
		logrus.WithError(err).Fatal("Failed to connect database")
	}
	defer sqlDB.Close()

	// ç”±äº GORM ä¸æ”¯æŒç›´æ¥ä½¿ç”¨ sql.DB è¿æ¥ DuckDB
	// æˆ‘ä»¬ä½¿ç”¨åŸç”Ÿ SQL æ¥åˆ›å»ºè¡¨å’Œæ‰§è¡Œæ“ä½œ
	// GORM å˜é‡ä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼Œä½†å®é™…ä½¿ç”¨ sqlDB è¿›è¡Œæ“ä½œ

	// è®¾ç½®è¿æ¥æ± å‚æ•°
	sqlDB.SetMaxIdleConns(10)
	sqlDB.SetMaxOpenConns(100)
	sqlDB.SetConnMaxLifetime(time.Hour)

	// ç¡®ä¿æ‰©å±•å·²åŠ è½½ï¼ˆduckdb-driver ä¼šè‡ªåŠ¨åŠ è½½ï¼Œä½†æˆ‘ä»¬å¯ä»¥éªŒè¯ï¼‰
	if err := ensureDuckDBExtensions(sqlDB); err != nil {
		logrus.WithError(err).Warn("Some DuckDB extensions may not be available")
	}

	// ä½¿ç”¨åŸç”Ÿ SQL åˆ›å»ºè¡¨ï¼ˆDuckDB å…¼å®¹ SQLite è¯­æ³•ï¼‰
	createTableSQL := `
	CREATE TABLE IF NOT EXISTS documents (
		id VARCHAR(255) PRIMARY KEY,
		collection_name VARCHAR(255) NOT NULL,
		data TEXT,
		embedding TEXT,
		content TEXT,
		created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
		updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
	);
	CREATE INDEX IF NOT EXISTS idx_documents_collection ON documents(collection_name);
	`
	if _, err := sqlDB.Exec(createTableSQL); err != nil {
		logrus.WithError(err).Fatal("Failed to create documents table")
	}

	// åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•ï¼ˆä½¿ç”¨ DuckDB FTS æ‰©å±•ï¼‰
	if err := createDuckDBFTSIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create FTS index, fulltext search may not work")
		// ä¸é€€å‡ºç¨‹åºï¼Œä½†è®°å½•é”™è¯¯ï¼Œåç»­ä¼šåœ¨æœç´¢æ—¶æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
	} else {
		logrus.Info("DuckDB FTS index created successfully")
	}

	// åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨ DuckDB VSS æ‰©å±•ï¼‰
	if err := createDuckDBVectorIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create vector index, vector search may not work")
		// ä¸é€€å‡ºç¨‹åºï¼Œä½†è®°å½•é”™è¯¯ï¼Œåç»­ä¼šåœ¨æœç´¢æ—¶æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
	} else {
		logrus.Info("DuckDB vector index created successfully")
	}

	// åˆå§‹åŒ–å›¾æ•°æ®åº“ï¼ˆä½¿ç”¨ Cayley é©±åŠ¨ï¼‰
	graphDBPath := filepath.Join(dbPath, "graph.db")
	graphDB, err = cayley_driver.NewGraph(graphDBPath)
	if err != nil {
		logrus.WithError(err).Fatal("Failed to create graph database")
	}
	defer graphDB.Close()

	// åˆå§‹åŒ– GORMï¼ˆä½¿ç”¨ SQLiteï¼Œå› ä¸º GORM å¯¹ DuckDB æ”¯æŒæœ‰é™ï¼‰
	// ä½¿ç”¨ä¸ DuckDB ç›¸åŒçš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œä½†é€šè¿‡ SQLite driver è¿æ¥
	sqliteDBPath := filepath.Join(dbPath, "browser.db")
	gormDB, err = gorm.Open(sqlite.Open(sqliteDBPath), &gorm.Config{})
	if err != nil {
		logrus.WithError(err).Fatal("Failed to initialize GORM")
	}

	// è‡ªåŠ¨è¿ç§»ï¼ˆç¡®ä¿è¡¨ç»“æ„æ­£ç¡®ï¼‰
	if err := gormDB.AutoMigrate(&Document{}); err != nil {
		logrus.WithError(err).Warn("Failed to auto migrate, but continuing")
	}

	logrus.Info("Database initialized successfully")

	// è®¾ç½® Gin è·¯ç”±
	r := gin.Default()

	// é…ç½® CORS
	config := cors.DefaultConfig()
	config.AllowAllOrigins = true
	config.AllowMethods = []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"}
	config.AllowHeaders = []string{"Origin", "Content-Type", "Accept", "Authorization"}
	r.Use(cors.New(config))

	// API è·¯ç”±
	api := r.Group("/api")
	{
		// æ•°æ®åº“ä¿¡æ¯
		api.GET("/db/info", getDBInfo)
		api.GET("/db/collections", getCollections)

		// é›†åˆæ“ä½œ
		api.GET("/collections/:name", getCollection)
		api.GET("/collections/:name/documents", getDocuments)
		api.GET("/collections/:name/documents/:id", getDocument)
		api.POST("/collections/:name/documents", createDocument)
		api.PUT("/collections/:name/documents/:id", updateDocument)
		api.DELETE("/collections/:name/documents/:id", deleteDocument)

		// å…¨æ–‡æœç´¢
		api.POST("/collections/:name/fulltext/search", fulltextSearch)

		// å‘é‡æœç´¢
		api.POST("/collections/:name/vector/search", vectorSearch)

		// å›¾æ•°æ®åº“æ“ä½œ
		api.POST("/graph/link", graphLink)
		api.DELETE("/graph/link", graphUnlink)
		api.GET("/graph/neighbors/:nodeId", graphNeighbors)
		api.POST("/graph/path", graphPath)
		api.POST("/graph/query", graphQuery)
	}

	port := os.Getenv("PORT")
	if port == "" {
		port = "40111"
	}

	logrus.WithField("port", port).Info("Server starting")
	if err := r.Run(":" + port); err != nil {
		logrus.WithError(err).Fatal("Failed to start server")
	}
}

// ensureDuckDBExtensions ç¡®ä¿ DuckDB æ‰©å±•å·²åŠ è½½
func ensureDuckDBExtensions(db *sql.DB) error {
	// æ£€æŸ¥æ‰©å±•æ˜¯å¦å·²åŠ è½½
	var count int
	err := db.QueryRow("SELECT COUNT(*) FROM duckdb_extensions() WHERE loaded = true AND extension_name IN ('fts', 'vss')").Scan(&count)
	if err != nil {
		// å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åŠ è½½
		logrus.Warn("Failed to check extensions, attempting to load manually")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
		return nil
	}

	if count < 2 {
		logrus.Warn("Some extensions may not be loaded, attempting to load")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
	}

	logrus.Info("DuckDB extensions verified")
	return nil
}

// createDuckDBFTSIndex åˆ›å»º DuckDB å…¨æ–‡æœç´¢ç´¢å¼•
func createDuckDBFTSIndex(db *sql.DB) error {
	// ä½¿ç”¨ DuckDB çš„ FTS æ‰©å±•åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
	// æ³¨æ„ï¼šDuckDB çš„ FTS ä½¿ç”¨ PRAGMA create_fts_index
	createFTSSQL := `PRAGMA create_fts_index('documents', 'id', 'content');`
	_, err := db.Exec(createFTSSQL)
	if err != nil {
		// å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
		if strings.Contains(err.Error(), "already exists") {
			logrus.Info("FTS index already exists")
			return nil
		}
		return fmt.Errorf("failed to create FTS index: %w", err)
	}

	logrus.Info("DuckDB FTS index created successfully")
	return nil
}

// createDuckDBVectorIndex åˆ›å»º DuckDB å‘é‡ç´¢å¼•
func createDuckDBVectorIndex(db *sql.DB) error {
	// ä½¿ç”¨ DuckDB çš„ VSS æ‰©å±•åˆ›å»º HNSW å‘é‡ç´¢å¼•
	// æ³¨æ„ï¼šéœ€è¦ç¡®ä¿ embedding åˆ—å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
	createVectorIndexSQL := `
	CREATE INDEX IF NOT EXISTS documents_embedding_idx 
	ON documents USING hnsw (embedding);
	`
	_, err := db.Exec(createVectorIndexSQL)
	if err != nil {
		// å¦‚æœç´¢å¼•å·²å­˜åœ¨æˆ–åˆ—ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Šä½†ä¸å¤±è´¥
		if strings.Contains(err.Error(), "already exists") {
			logrus.Info("Vector index already exists")
			return nil
		}
		// å¦‚æœ embedding åˆ—ä¸å­˜åœ¨ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼ˆå› ä¸ºå®ƒæ˜¯å¯é€‰çš„ï¼‰
		if strings.Contains(err.Error(), "does not exist") || strings.Contains(err.Error(), "column") {
			logrus.Warn("Embedding column may not exist yet, vector index will be created when needed")
			return nil
		}
		return fmt.Errorf("failed to create vector index: %w", err)
	}

	logrus.Info("DuckDB vector index created successfully")
	return nil
}

// getDBInfo è·å–æ•°æ®åº“ä¿¡æ¯
func getDBInfo(c *gin.Context) {
	c.JSON(http.StatusOK, gin.H{
		"name": "browser-db",
		"path": os.Getenv("DB_PATH"),
	})
}

// getCollections è·å–æ‰€æœ‰é›†åˆ
func getCollections(c *gin.Context) {
	var collections []string
	if err := gormDB.Model(&Document{}).
		Distinct("collection_name").
		Pluck("collection_name", &collections).Error; err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	collectionInfos := make([]CollectionInfo, len(collections))
	for i, name := range collections {
		collectionInfos[i] = CollectionInfo{
			Name:   name,
			Schema: make(map[string]interface{}),
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"collections": collectionInfos,
	})
}

// getCollection è·å–é›†åˆä¿¡æ¯
func getCollection(c *gin.Context) {
	name := c.Param("name")

	// æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
	var count int64
	if err := gormDB.Model(&Document{}).
		Where("collection_name = ?", name).
		Count(&count).Error; err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"name":   name,
		"exists": count > 0,
		"count":  count,
	})
}

// getDocuments è·å–é›†åˆä¸­çš„æ‰€æœ‰æ–‡æ¡£
func getDocuments(c *gin.Context) {
	name := c.Param("name")
	limitStr := c.DefaultQuery("limit", "100")
	skipStr := c.DefaultQuery("skip", "0")
	tagFilter := c.Query("tag")

	limit, _ := strconv.Atoi(limitStr)
	skip, _ := strconv.Atoi(skipStr)

	logrus.WithFields(logrus.Fields{
		"collection": name,
		"limit":      limit,
		"skip":       skip,
		"tag":        tagFilter,
	}).Info("ğŸ“„ getDocuments")

	var docs []Document
	query := gormDB.Where("collection_name = ?", name)

	// å¦‚æœæŒ‡å®šäº† tag è¿‡æ»¤ï¼Œéœ€è¦åœ¨ JSON æ•°æ®ä¸­æœç´¢
	if tagFilter != "" {
		// ä½¿ç”¨ JSON æŸ¥è¯¢ï¼ˆSQLite æ”¯æŒ JSON1 æ‰©å±•ï¼‰
		query = query.Where("json_extract(data, '$.tags') LIKE ?", "%"+tagFilter+"%")
	}

	// è·å–æ€»æ•°
	var total int64
	if err := query.Model(&Document{}).Count(&total).Error; err != nil {
		logrus.WithError(err).Error("âŒ Failed to count documents")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// åˆ†é¡µæŸ¥è¯¢
	if err := query.Offset(skip).Limit(limit).Find(&docs).Error; err != nil {
		logrus.WithError(err).Error("âŒ Failed to get documents")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	logrus.WithFields(logrus.Fields{
		"returned": len(docs),
		"total":    total,
		"skip":     skip,
		"limit":    limit,
	}).Info("ğŸ“„ Returning documents")

	response := make([]DocumentResponse, len(docs))
	for i, doc := range docs {
		var data map[string]interface{}
		if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			data = make(map[string]interface{})
		}
		response[i] = DocumentResponse{
			ID:   doc.ID,
			Data: data,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"documents": response,
		"total":     total,
		"skip":      skip,
		"limit":     limit,
	})
}

// getDocument è·å–å•ä¸ªæ–‡æ¡£
func getDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	var doc Document
	if err := gormDB.Where("collection_name = ? AND id = ?", name, id).First(&doc).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			c.JSON(http.StatusNotFound, ErrorResponse{Error: "Document not found"})
		} else {
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		}
		return
	}

	var data map[string]interface{}
	if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, DocumentResponse{
		ID:   doc.ID,
		Data: data,
	})
}

// createDocument åˆ›å»ºæ–‡æ¡£
func createDocument(c *gin.Context) {
	name := c.Param("name")

	var data map[string]interface{}
	if err := c.ShouldBindJSON(&data); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// ç”Ÿæˆ IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
	id, ok := data["id"].(string)
	if !ok || id == "" {
		id = generateID()
		data["id"] = id
	}

	// å°†æ•°æ®åºåˆ—åŒ–ä¸º JSON
	dataJSON, err := json.Marshal(data)
	if err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// æå–æ–‡æœ¬å†…å®¹ç”¨äºå…¨æ–‡æœç´¢
	content := extractTextFromData(string(dataJSON))

	// æå– embeddingï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	embeddingStr := ""
	if embeddingField, ok := data["embedding"]; ok {
		embeddingJSON, err := json.Marshal(embeddingField)
		if err == nil {
			embeddingStr = string(embeddingJSON)
		}
	}

	doc := Document{
		ID:             id,
		CollectionName: name,
		Data:           string(dataJSON),
		Content:        content,
		Embedding:      embeddingStr,
	}

	if err := gormDB.Create(&doc).Error; err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤

	c.JSON(http.StatusCreated, DocumentResponse{
		ID:   doc.ID,
		Data: data,
	})
}

// updateDocument æ›´æ–°æ–‡æ¡£
func updateDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	var doc Document
	if err := gormDB.Where("collection_name = ? AND id = ?", name, id).First(&doc).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			c.JSON(http.StatusNotFound, ErrorResponse{Error: "Document not found"})
		} else {
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		}
		return
	}

	var updates map[string]interface{}
	if err := c.ShouldBindJSON(&updates); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// è§£æç°æœ‰æ•°æ®
	var data map[string]interface{}
	if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// åˆå¹¶æ›´æ–°
	for k, v := range updates {
		data[k] = v
	}

	// ç¡®ä¿ ID ä¸å˜
	data["id"] = id

	// åºåˆ—åŒ–å› JSON
	dataJSON, err := json.Marshal(data)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// æå–æ–‡æœ¬å†…å®¹ç”¨äºå…¨æ–‡æœç´¢
	content := extractTextFromData(string(dataJSON))

	// æå– embeddingï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	embeddingStr := ""
	if embeddingField, ok := data["embedding"]; ok {
		embeddingJSON, err := json.Marshal(embeddingField)
		if err == nil {
			embeddingStr = string(embeddingJSON)
		}
	}

	doc.Data = string(dataJSON)
	doc.Content = content
	doc.Embedding = embeddingStr
	if err := gormDB.Save(&doc).Error; err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤

	c.JSON(http.StatusOK, DocumentResponse{
		ID:   doc.ID,
		Data: data,
	})
}

// deleteDocument åˆ é™¤æ–‡æ¡£
func deleteDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	if err := gormDB.Where("collection_name = ? AND id = ?", name, id).Delete(&Document{}).Error; err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤

	c.JSON(http.StatusOK, gin.H{"message": "Document deleted"})
}

// fulltextSearch å…¨æ–‡æœç´¢
func fulltextSearch(c *gin.Context) {
	name := c.Param("name")

	var req FulltextSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	start := time.Now()

	// æ£€æŸ¥ FTS ç´¢å¼•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•åˆ›å»º
	var indexExists bool
	checkSQL := `SELECT COUNT(*) FROM pragma_table_info('documents') WHERE name = 'content'`
	var count int
	if err := sqlDB.QueryRow(checkSQL).Scan(&count); err == nil && count > 0 {
		// æ£€æŸ¥ FTS ç´¢å¼•
		indexCheckSQL := `SELECT COUNT(*) FROM duckdb_indexes() WHERE index_name LIKE '%fts%'`
		if err := sqlDB.QueryRow(indexCheckSQL).Scan(&count); err == nil && count > 0 {
			indexExists = true
		}
	}

	if !indexExists {
		logrus.Warn("FTS index does not exist, attempting to create it")
		if err := createDuckDBFTSIndex(sqlDB); err != nil {
			logrus.WithError(err).Error("Failed to create FTS index")
			c.JSON(http.StatusInternalServerError, ErrorResponse{
				Error: fmt.Sprintf("FTS index is not available: %v", err),
			})
			return
		}
	}

	// ä½¿ç”¨ DuckDB FTS è¿›è¡Œå…¨æ–‡æœç´¢
	// DuckDB çš„ FTS ä½¿ç”¨ MATCH æ“ä½œç¬¦ï¼Œä½†è¯­æ³•å¯èƒ½ä¸åŒ
	// å…ˆå°è¯•ä½¿ç”¨ FTS æŸ¥è¯¢ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ° LIKE æŸ¥è¯¢
	query := `
	SELECT id, collection_name, data, 1.0 as score
	FROM documents
	WHERE collection_name = ? 
	  AND content MATCH ?
	LIMIT ?
	`

	rows, err := sqlDB.Query(query, name, req.Query, req.Limit)
	if err != nil {
		// å¦‚æœ FTS æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨ LIKE æŸ¥è¯¢ä½œä¸ºå›é€€
		logrus.WithError(err).Warn("FTS query failed, using LIKE query as fallback")
		query = `
		SELECT id, collection_name, data, 1.0 as score
		FROM documents
		WHERE collection_name = ? 
		  AND content LIKE ?
		LIMIT ?
		`
		searchPattern := "%" + req.Query + "%"
		rows, err = sqlDB.Query(query, name, searchPattern, req.Limit)
		if err != nil {
			logrus.WithError(err).Error("Fulltext search failed")
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
			return
		}
	}
	defer rows.Close()

	var results []gin.H
	for rows.Next() {
		var docID, collectionName, dataJSON string
		var score float64
		if err := rows.Scan(&docID, &collectionName, &dataJSON, &score); err != nil {
			logrus.WithError(err).Error("Failed to scan row")
			continue
		}

		// æ£€æŸ¥é˜ˆå€¼ï¼ˆæ³¨æ„ï¼šDuckDB FTS çš„åˆ†æ•°å¯èƒ½ä¸åŒï¼Œè¿™é‡Œä½¿ç”¨ç®€å•çš„è¿‡æ»¤ï¼‰
		if req.Threshold > 0 && score < req.Threshold {
			continue
		}

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			continue
		}

		results = append(results, gin.H{
			"document": DocumentResponse{
				ID:   docID,
				Data: data,
			},
			"score": score,
		})
	}

	took := time.Since(start).Milliseconds()

	c.JSON(http.StatusOK, gin.H{
		"results": results,
		"query":   req.Query,
		"took":    took,
	})
}

// vectorSearch å‘é‡æœç´¢
func vectorSearch(c *gin.Context) {
	name := c.Param("name")

	bodyBytes, _ := io.ReadAll(c.Request.Body)
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	var req VectorSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		logrus.WithError(err).Error("Failed to bind JSON")
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: fmt.Sprintf("Invalid request format: %v", err),
		})
		return
	}

	logrus.WithFields(logrus.Fields{
		"collection":   name,
		"hasQuery":     len(req.Query) > 0,
		"hasQueryText": req.QueryText != "",
		"queryText":    req.QueryText,
		"limit":        req.Limit,
		"field":        req.Field,
	}).Info("Vector search request")

	// å¦‚æœæä¾›äº†æ–‡æœ¬æŸ¥è¯¢ï¼Œç”Ÿæˆ embedding
	var queryVector []float64
	if req.QueryText != "" {
		logrus.WithField("queryText", req.QueryText).Info("ğŸ”„ Generating embedding from text")
		embedding, err := generateEmbeddingFromText(req.QueryText)
		if err != nil {
			logrus.WithError(err).Error("âŒ Failed to generate embedding from text")
			c.JSON(http.StatusBadRequest, ErrorResponse{
				Error: fmt.Sprintf("Failed to generate embedding from text: %v", err),
			})
			return
		}
		queryVector = embedding
		logrus.WithFields(logrus.Fields{
			"dimension": len(queryVector),
			"first3":    queryVector[:min(3, len(queryVector))],
		}).Info("âœ… Generated embedding")
	} else if len(req.Query) > 0 {
		queryVector = req.Query
		logrus.WithField("dimension", len(queryVector)).Info("Using provided vector")
	} else {
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: "Either 'query' (vector) or 'query_text' (text) must be provided",
		})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	if req.Field == "" {
		req.Field = "embedding"
	}

	// ç”±äº embedding å­˜å‚¨ä¸º JSON å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬ä½¿ç”¨å†…å­˜è®¡ç®—è¿›è¡Œå‘é‡æœç´¢
	// æœªæ¥å¯ä»¥ä¼˜åŒ–ä¸ºç›´æ¥åœ¨ DuckDB ä¸­å­˜å‚¨æ•°ç»„ç±»å‹å¹¶ä½¿ç”¨ VSS æ‰©å±•
	// ç›®å‰ä½¿ç”¨å›é€€æ–¹æ¡ˆï¼ˆå†…å­˜è®¡ç®—ï¼‰
	vectorSearchFallback(c, name, req, queryVector)
}

// vectorSearchFallback å‘é‡æœç´¢çš„å›é€€æ–¹æ¡ˆï¼ˆå†…å­˜è®¡ç®—ï¼‰
func vectorSearchFallback(c *gin.Context, name string, req VectorSearchRequest, queryVector []float64) {
	start := time.Now()

	// è·å–é›†åˆä¸­çš„æ‰€æœ‰æ–‡æ¡£
	var docs []Document
	if err := gormDB.Where("collection_name = ?", name).Find(&docs).Error; err != nil {
		logrus.WithError(err).Error("Failed to get documents for vector search")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	type VectorResult struct {
		Document DocumentResponse
		Score    float64
	}

	var results []VectorResult

	// éå†æ–‡æ¡£ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
	for _, doc := range docs {
		var data map[string]interface{}
		if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
			continue
		}

		// è·å–æ–‡æ¡£çš„ embedding
		embeddingField, ok := data[req.Field]
		if !ok {
			continue
		}

		// è½¬æ¢ embedding ä¸º []float64
		var docVector []float64
		switch v := embeddingField.(type) {
		case []interface{}:
			docVector = make([]float64, len(v))
			for i, val := range v {
				if f, ok := val.(float64); ok {
					docVector[i] = f
				} else if f, ok := val.(float32); ok {
					docVector[i] = float64(f)
				} else {
					docVector = nil
					break
				}
			}
		case []float64:
			docVector = v
		default:
			continue
		}

		if docVector == nil || len(docVector) == 0 {
			continue
		}

		// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
		similarity := cosineSimilarity(queryVector, docVector)

		// åº”ç”¨é˜ˆå€¼è¿‡æ»¤ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
		if req.Threshold > 0 && similarity < req.Threshold {
			continue
		}

		results = append(results, VectorResult{
			Document: DocumentResponse{
				ID:   doc.ID,
				Data: data,
			},
			Score: similarity,
		})
	}

	// æŒ‰ç›¸ä¼¼åº¦æ’åºï¼ˆé™åºï¼‰
	for i := 0; i < len(results)-1; i++ {
		for j := i + 1; j < len(results); j++ {
			if results[i].Score < results[j].Score {
				results[i], results[j] = results[j], results[i]
			}
		}
	}

	// é™åˆ¶ç»“æœæ•°é‡
	if len(results) > req.Limit {
		results = results[:req.Limit]
	}

	took := time.Since(start).Milliseconds()

	// è½¬æ¢ä¸ºå“åº”æ ¼å¼
	responseResults := make([]gin.H, len(results))
	for i, r := range results {
		responseResults[i] = gin.H{
			"document": r.Document,
			"score":    r.Score,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"results": responseResults,
		"query":   req.QueryText,
		"took":    took,
	})
}

// generateID ç”Ÿæˆæ–‡æ¡£ ID
func generateID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

// DuckDB çš„ FTS ç´¢å¼•æ˜¯è‡ªåŠ¨ç»´æŠ¤çš„ï¼Œæ— éœ€æ‰‹åŠ¨æ›´æ–°æˆ–åˆ é™¤

// extractTextFromData ä» JSON æ•°æ®ä¸­æå–æ–‡æœ¬å†…å®¹
func extractTextFromData(dataJSON string) string {
	var data map[string]interface{}
	if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
		return ""
	}

	var parts []string
	for k, v := range data {
		if k == "id" || k == "_rev" || k == "embedding" {
			continue
		}
		if str, ok := v.(string); ok {
			parts = append(parts, str)
		} else if arr, ok := v.([]interface{}); ok {
			// å¤„ç†æ•°ç»„å­—æ®µï¼ˆå¦‚ tagsï¼‰
			for _, item := range arr {
				if str, ok := item.(string); ok {
					parts = append(parts, str)
				}
			}
		} else {
			parts = append(parts, fmt.Sprintf("%v", v))
		}
	}
	return strings.Join(parts, " ")
}

// DuckDB çš„ FTS ç´¢å¼•æ˜¯è‡ªåŠ¨ç»´æŠ¤çš„ï¼Œæ— éœ€æ‰‹åŠ¨é‡æ–°ç´¢å¼•

// DashScope API ç»“æ„
type DashScopeEmbeddingRequest struct {
	Model string         `json:"model"`
	Input DashScopeInput `json:"input"`
}

type DashScopeInput struct {
	Texts []string `json:"texts"`
}

type DashScopeEmbeddingResponse struct {
	Output DashScopeOutput `json:"output"`
}

type DashScopeOutput struct {
	Embeddings []DashScopeEmbedding `json:"embeddings"`
}

type DashScopeEmbedding struct {
	Embedding []float32 `json:"embedding"`
}

// generateEmbeddingFromText ä½¿ç”¨ DashScope API ä»æ–‡æœ¬ç”Ÿæˆ embedding
func generateEmbeddingFromText(text string) ([]float64, error) {
	apiKey := os.Getenv("DASHSCOPE_API_KEY")
	if apiKey == "" {
		return nil, fmt.Errorf("DASHSCOPE_API_KEY environment variable is not set")
	}

	url := "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding"

	reqBody := DashScopeEmbeddingRequest{
		Model: "text-embedding-v4",
		Input: DashScopeInput{
			Texts: []string{text},
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to send request: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("API request failed with status %d: %s", resp.StatusCode, string(body))
	}

	var apiResp DashScopeEmbeddingResponse
	if err := json.Unmarshal(body, &apiResp); err != nil {
		return nil, fmt.Errorf("failed to unmarshal response: %w", err)
	}

	if len(apiResp.Output.Embeddings) == 0 {
		return nil, fmt.Errorf("no embedding returned")
	}

	embedding := apiResp.Output.Embeddings[0].Embedding
	result := make([]float64, len(embedding))
	for i, v := range embedding {
		result[i] = float64(v)
	}

	return result, nil
}

// min è¾…åŠ©å‡½æ•°
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// cosineSimilarity è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
func cosineSimilarity(a, b []float64) float64 {
	if len(a) != len(b) {
		return 0.0
	}

	var dotProduct, normA, normB float64
	for i := 0; i < len(a); i++ {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0.0
	}

	return dotProduct / (sqrt(normA) * sqrt(normB))
}

// sqrt è®¡ç®—å¹³æ–¹æ ¹ï¼ˆä½¿ç”¨æ ‡å‡†åº“ï¼‰
func sqrt(x float64) float64 {
	return math.Sqrt(x)
}

// ========================================
// å›¾æ•°æ®åº“ API å¤„ç†å‡½æ•°
// ========================================

type GraphLinkRequest struct {
	From     string `json:"from" binding:"required"`
	Relation string `json:"relation" binding:"required"`
	To       string `json:"to" binding:"required"`
}

type GraphPathRequest struct {
	From      string   `json:"from" binding:"required"`
	To        string   `json:"to" binding:"required"`
	MaxDepth  int      `json:"max_depth"`
	Relations []string `json:"relations,omitempty"`
}

type GraphQueryRequest struct {
	Query string `json:"query" binding:"required"`
}

// graphLink åˆ›å»ºå›¾å…³ç³»é“¾æ¥
func graphLink(c *gin.Context) {
	var req GraphLinkRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	if err := graphDB.Link(dbContext, req.From, req.Relation, req.To); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"message":  "Link created successfully",
		"from":     req.From,
		"relation": req.Relation,
		"to":       req.To,
	})
}

// graphUnlink åˆ é™¤å›¾å…³ç³»é“¾æ¥
func graphUnlink(c *gin.Context) {
	var req GraphLinkRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	if err := graphDB.Unlink(dbContext, req.From, req.Relation, req.To); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"message":  "Link deleted successfully",
		"from":     req.From,
		"relation": req.Relation,
		"to":       req.To,
	})
}

// graphNeighbors è·å–èŠ‚ç‚¹çš„é‚»å±…
func graphNeighbors(c *gin.Context) {
	nodeID := c.Param("nodeId")
	relation := c.DefaultQuery("relation", "")

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	neighbors, err := graphDB.GetNeighbors(dbContext, nodeID, relation)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"node_id":   nodeID,
		"relation":  relation,
		"neighbors": neighbors,
	})
}

// graphPath æŸ¥æ‰¾ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è·¯å¾„
func graphPath(c *gin.Context) {
	var req GraphPathRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if req.MaxDepth == 0 {
		req.MaxDepth = 5
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	var paths [][]string
	var err error

	// Cayley é©±åŠ¨çš„ FindPath åªæ¥å—å•ä¸ª predicateï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
	predicate := ""
	if len(req.Relations) > 0 {
		predicate = req.Relations[0]
	}

	paths, err = graphDB.FindPath(dbContext, req.From, req.To, req.MaxDepth, predicate)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"from":  req.From,
		"to":    req.To,
		"paths": paths,
	})
}

// graphQuery æ‰§è¡Œå›¾æŸ¥è¯¢
func graphQuery(c *gin.Context) {
	var req GraphQueryRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	query := graphDB.Query()
	if query == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Query builder not available",
		})
		return
	}

	logrus.WithField("query", req.Query).Info("ğŸ” è§£ææŸ¥è¯¢å­—ç¬¦ä¸²")

	// è§£æ V('nodeId')
	if !strings.HasPrefix(req.Query, "V(") {
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: "æŸ¥è¯¢å¿…é¡»ä»¥ V('nodeId') å¼€å§‹",
		})
		return
	}

	// æå–èŠ‚ç‚¹ID
	var nodeID string
	var vEndIndex int

	nodeStart := strings.Index(req.Query, "('")
	if nodeStart == -1 {
		nodeStart = strings.Index(req.Query, "(\"")
		if nodeStart == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{
				Error: "æ— æ³•è§£æèŠ‚ç‚¹IDï¼Œæ ¼å¼åº”ä¸º V('nodeId') æˆ– V(\"nodeId\")",
			})
			return
		}
		relEnd := strings.Index(req.Query[nodeStart+2:], "\")")
		if relEnd == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{Error: "èŠ‚ç‚¹IDæ ¼å¼é”™è¯¯"})
			return
		}
		nodeID = req.Query[nodeStart+2 : nodeStart+2+relEnd]
		vEndIndex = nodeStart + 2 + relEnd + 2
	} else {
		relEnd := strings.Index(req.Query[nodeStart+2:], "')")
		if relEnd == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{Error: "èŠ‚ç‚¹IDæ ¼å¼é”™è¯¯"})
			return
		}
		nodeID = req.Query[nodeStart+2 : nodeStart+2+relEnd]
		vEndIndex = nodeStart + 2 + relEnd + 2
	}

	logrus.WithField("node_id", nodeID).Info("ğŸ“Œ æå–èŠ‚ç‚¹ID")

	// åˆ›å»ºåŸºç¡€æŸ¥è¯¢
	queryImpl := query.V(nodeID)
	if queryImpl == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "åˆ›å»ºæŸ¥è¯¢å¤±è´¥",
		})
		return
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰ .Out() æˆ– .In()
	remainingQuery := ""
	if vEndIndex < len(req.Query) {
		remainingQuery = req.Query[vEndIndex:]
	}
	logrus.WithField("remaining_query", remainingQuery).Info("ğŸ“‹ å‰©ä½™æŸ¥è¯¢éƒ¨åˆ†")

	if strings.HasPrefix(remainingQuery, ".Out(") {
		relStart := strings.Index(remainingQuery, "('")
		if relStart == -1 {
			relStart = strings.Index(remainingQuery, "(\"")
			if relStart == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "æ— æ³•è§£æå…³ç³»åç§°"})
				return
			}
			relEnd := strings.Index(remainingQuery[relStart+2:], "\")")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (Out)")
			queryImpl = queryImpl.Out(relation)
		} else {
			relEnd := strings.Index(remainingQuery[relStart+2:], "')")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (Out)")
			queryImpl = queryImpl.Out(relation)
		}
	} else if strings.HasPrefix(remainingQuery, ".In(") {
		relStart := strings.Index(remainingQuery, "('")
		if relStart == -1 {
			relStart = strings.Index(remainingQuery, "(\"")
			if relStart == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "æ— æ³•è§£æå…³ç³»åç§°"})
				return
			}
			relEnd := strings.Index(remainingQuery[relStart+2:], "\")")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (In)")
			queryImpl = queryImpl.In(relation)
		} else {
			relEnd := strings.Index(remainingQuery[relStart+2:], "')")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (In)")
			queryImpl = queryImpl.In(relation)
		}
	}

	if queryImpl == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "æ„å»ºæŸ¥è¯¢å¤±è´¥",
		})
		return
	}

	// æ‰§è¡ŒæŸ¥è¯¢
	logrus.Info("ğŸš€ æ‰§è¡Œå›¾æŸ¥è¯¢...")
	queryResults, err := queryImpl.All(dbContext)
	if err != nil {
		logrus.WithError(err).Info("âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	logrus.WithField("count", len(queryResults)).Info("âœ… æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°ç»“æœ")

	// è½¬æ¢ç»“æœ
	results := make([]gin.H, len(queryResults))
	for i, r := range queryResults {
		results[i] = gin.H{
			"subject":   r.Subject,
			"predicate": r.Predicate,
			"object":    r.Object,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"query":   req.Query,
		"results": results,
	})
}
