package main

import (
	"bytes"
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"net/http"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"github.com/gin-contrib/cors"
	"github.com/gin-gonic/gin"
	cayley_driver "github.com/mozhou-tech/sqlite-ai-driver/pkg/cayley-driver"
	_ "github.com/mozhou-tech/sqlite-ai-driver/pkg/duckdb-driver"
	"github.com/mozhou-tech/sqlite-ai-driver/pkg/sego"
	_ "github.com/mozhou-tech/sqlite-ai-driver/pkg/sqlite3-driver"
	"github.com/sirupsen/logrus"
	"gorm.io/gorm"
)

var (
	gormDB    *gorm.DB
	sqlDB     *sql.DB
	graphDB   cayley_driver.Graph
	dbContext context.Context
)

// Document æ–‡æ¡£æ¨¡å‹
type Document struct {
	ID             string    `gorm:"primaryKey;type:varchar(255);not null"`
	CollectionName string    `gorm:"type:varchar(255);not null;index"`
	Data           string    `gorm:"type:text"`     // JSON æ ¼å¼å­˜å‚¨
	Embedding      string    `gorm:"type:DOUBLE[]"` // å‘é‡æ•°æ®ï¼Œå­˜å‚¨ä¸ºæ•°ç»„
	Content        string    `gorm:"type:text"`     // æå–çš„æ–‡æœ¬å†…å®¹ï¼Œç”¨äºå…¨æ–‡æœç´¢
	CreatedAt      time.Time `gorm:"autoCreateTime"`
	UpdatedAt      time.Time `gorm:"autoUpdateTime"`
}

// TableName æŒ‡å®šè¡¨å
func (Document) TableName() string {
	return "documents"
}

// DatabaseConfig æ•°æ®åº“é…ç½®
type DatabaseConfig struct {
	Name string `json:"name"`
	Path string `json:"path"`
}

// CollectionInfo é›†åˆä¿¡æ¯
type CollectionInfo struct {
	Name   string                 `json:"name"`
	Schema map[string]interface{} `json:"schema"`
}

// DocumentResponse æ–‡æ¡£å“åº”
type DocumentResponse struct {
	ID   string                 `json:"id"`
	Data map[string]interface{} `json:"data"`
}

// FulltextSearchRequest å…¨æ–‡æœç´¢è¯·æ±‚
type FulltextSearchRequest struct {
	Collection string  `json:"collection"`
	Query      string  `json:"query"`
	Limit      int     `json:"limit"`
	Threshold  float64 `json:"threshold"`
}

// VectorSearchRequest å‘é‡æœç´¢è¯·æ±‚
type VectorSearchRequest struct {
	Collection string    `json:"collection,omitempty"`
	Query      []float64 `json:"query,omitempty"`
	QueryText  string    `json:"query_text,omitempty"`
	Limit      int       `json:"limit,omitempty"`
	Field      string    `json:"field,omitempty"`
	Threshold  float64   `json:"threshold,omitempty"`
}

// ErrorResponse é”™è¯¯å“åº”
type ErrorResponse struct {
	Error string `json:"error"`
}

func main() {
	// é¢„åŠ è½½ sego è¯å…¸
	if err := sego.Init(); err != nil {
		logrus.WithError(err).Warn("Failed to initialize sego dictionary")
	}

	// ä»ç¯å¢ƒå˜é‡è¯»å–æ•°æ®åº“é…ç½®
	dbName := os.Getenv("DB_NAME")
	if dbName == "" {
		dbName = "browser-db"
	}

	dbPath := os.Getenv("DB_PATH")
	if dbPath == "" {
		dbPath = "./data/browser-db"
	}

	// ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(dbPath, 0755); err != nil {
		logrus.WithError(err).Fatal("Failed to create data directory")
	}

	ctx := context.Background()
	dbContext = ctx

	// åˆå§‹åŒ– DuckDB æ•°æ®åº“
	// DuckDB éœ€è¦æ–‡ä»¶è·¯å¾„ï¼Œè€Œä¸æ˜¯ç›®å½•è·¯å¾„
	duckDBPath := filepath.Join(dbPath, "browser.db")
	// è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œé¿å…å·¥ä½œç›®å½•é—®é¢˜
	absDBPath, err := filepath.Abs(duckDBPath)
	if err != nil {
		logrus.WithError(err).Fatal("Failed to get absolute path")
	}
	logrus.WithField("db_path", absDBPath).Info("Database path")

	// ç›´æ¥ä½¿ç”¨ database/sql è¿æ¥ DuckDB
	sqlDB, err = sql.Open("duckdb", absDBPath)
	if err != nil {
		logrus.WithError(err).Fatal("Failed to connect database")
	}
	defer sqlDB.Close()

	// ç”±äº GORM ä¸æ”¯æŒç›´æ¥ä½¿ç”¨ sql.DB è¿æ¥ DuckDB
	// æˆ‘ä»¬ä½¿ç”¨åŸç”Ÿ SQL æ¥åˆ›å»ºè¡¨å’Œæ‰§è¡Œæ“ä½œ
	// GORM å˜é‡ä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼Œä½†å®é™…ä½¿ç”¨ sqlDB è¿›è¡Œæ“ä½œ

	// è®¾ç½®è¿æ¥æ± å‚æ•°
	sqlDB.SetMaxIdleConns(10)
	sqlDB.SetMaxOpenConns(100)
	sqlDB.SetConnMaxLifetime(time.Hour)

	// ç¡®ä¿æ‰©å±•å·²åŠ è½½ï¼ˆduckdb-driver ä¼šè‡ªåŠ¨åŠ è½½ï¼Œä½†æˆ‘ä»¬å¯ä»¥éªŒè¯ï¼‰
	if err := ensureDuckDBExtensions(sqlDB); err != nil {
		logrus.WithError(err).Warn("Some DuckDB extensions may not be available")
	}

	// ä½¿ç”¨åŸç”Ÿ SQL åˆ›å»ºè¡¨ï¼ˆDuckDB å…¼å®¹ SQLite è¯­æ³•ï¼‰
	createTableSQL := `
	CREATE TABLE IF NOT EXISTS documents (
		id VARCHAR(255) PRIMARY KEY,
		collection_name VARCHAR(255) NOT NULL,
		data TEXT,
		embedding TEXT,
		content TEXT,
		content_tokens TEXT,
		created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
		updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
	);
	CREATE INDEX IF NOT EXISTS idx_documents_collection ON documents(collection_name);
	`
	if _, err := sqlDB.Exec(createTableSQL); err != nil {
		logrus.WithError(err).Fatal("Failed to create documents table")
	}

	// åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•ï¼ˆä½¿ç”¨ DuckDB FTS æ‰©å±•ï¼‰
	if err := createDuckDBFTSIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create FTS index, fulltext search may not work")
		// ä¸é€€å‡ºç¨‹åºï¼Œä½†è®°å½•é”™è¯¯ï¼Œåç»­ä¼šåœ¨æœç´¢æ—¶æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
	} else {
		logrus.Info("DuckDB FTS index created successfully")
	}

	// åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨ DuckDB VSS æ‰©å±•ï¼‰
	if err := createDuckDBVectorIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create vector index, vector search may not work")
		// ä¸é€€å‡ºç¨‹åºï¼Œä½†è®°å½•é”™è¯¯ï¼Œåç»­ä¼šåœ¨æœç´¢æ—¶æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
	} else {
		logrus.Info("DuckDB vector index created successfully")
	}

	// åˆå§‹åŒ–å›¾æ•°æ®åº“ï¼ˆä½¿ç”¨ Cayley é©±åŠ¨ï¼‰
	// ä½¿ç”¨ dbPath ä½œä¸º workingDirï¼Œç›¸å¯¹è·¯å¾„ä¼šæ„å»ºåˆ° {dbPath}/graph/ ç›®å½•
	graphDBPath := "graph.db"
	graphDB, err = cayley_driver.NewGraphWithNamespace(dbPath, graphDBPath, "")
	if err != nil {
		logrus.WithError(err).Fatal("Failed to create graph database")
	}
	defer graphDB.Close()

	// æ³¨æ„ï¼šç”±äº GORM ä¸æ”¯æŒç›´æ¥ä½¿ç”¨ sql.DB è¿æ¥ DuckDB
	// æˆ‘ä»¬ä½¿ç”¨åŸç”Ÿ SQL æ¥æ‰§è¡Œæ‰€æœ‰æ“ä½œ
	// å¦‚æœéœ€è¦ä½¿ç”¨ GORMï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ github.com/alifiroozi80/duckdb é©±åŠ¨

	logrus.Info("Database initialized successfully")

	// è®¾ç½® Gin è·¯ç”±
	r := gin.Default()

	// é…ç½® CORS
	config := cors.DefaultConfig()
	config.AllowAllOrigins = true
	config.AllowMethods = []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"}
	config.AllowHeaders = []string{"Origin", "Content-Type", "Accept", "Authorization"}
	r.Use(cors.New(config))

	// API è·¯ç”±
	api := r.Group("/api")
	{
		// æ•°æ®åº“ä¿¡æ¯
		api.GET("/db/info", getDBInfo)
		api.GET("/db/collections", getCollections)

		// é›†åˆæ“ä½œ
		api.GET("/collections/:name", getCollection)
		api.GET("/collections/:name/documents", getDocuments)
		api.GET("/collections/:name/documents/:id", getDocument)
		api.POST("/collections/:name/documents", createDocument)
		api.PUT("/collections/:name/documents/:id", updateDocument)
		api.DELETE("/collections/:name/documents/:id", deleteDocument)

		// å…¨æ–‡æœç´¢
		api.POST("/collections/:name/fulltext/search", fulltextSearch)

		// å‘é‡æœç´¢
		api.POST("/collections/:name/vector/search", vectorSearch)

		// å›¾æ•°æ®åº“æ“ä½œ
		api.POST("/graph/link", graphLink)
		api.DELETE("/graph/link", graphUnlink)
		api.GET("/graph/neighbors/:nodeId", graphNeighbors)
		api.POST("/graph/path", graphPath)
		api.POST("/graph/query", graphQuery)
	}

	port := os.Getenv("PORT")
	if port == "" {
		port = "40111"
	}

	logrus.WithField("port", port).Info("Server starting")
	if err := r.Run(":" + port); err != nil {
		logrus.WithError(err).Fatal("Failed to start server")
	}
}

// columnExists æ£€æŸ¥è¡¨ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šåˆ—
func columnExists(db *sql.DB, tableName, columnName string) (bool, error) {
	// DuckDB ä½¿ç”¨ PRAGMA table_info æ¥è·å–è¡¨ä¿¡æ¯
	query := `SELECT COUNT(*) FROM pragma_table_info(?) WHERE name = ?`
	var count int
	err := db.QueryRow(query, tableName, columnName).Scan(&count)
	if err != nil {
		return false, err
	}
	return count > 0, nil
}

// ensureDuckDBExtensions ç¡®ä¿ DuckDB æ‰©å±•å·²åŠ è½½
func ensureDuckDBExtensions(db *sql.DB) error {
	// æ£€æŸ¥æ‰©å±•æ˜¯å¦å·²åŠ è½½
	var count int
	err := db.QueryRow("SELECT COUNT(*) FROM duckdb_extensions() WHERE loaded = true AND extension_name IN ('fts', 'vss')").Scan(&count)
	if err != nil {
		// å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åŠ è½½
		logrus.Warn("Failed to check extensions, attempting to load manually")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
		return nil
	}

	if count < 2 {
		logrus.Warn("Some extensions may not be loaded, attempting to load")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
	}

	logrus.Info("DuckDB extensions verified")
	return nil
}

// createDuckDBFTSIndex åˆ›å»º DuckDB å…¨æ–‡æœç´¢ç´¢å¼•
func createDuckDBFTSIndex(db *sql.DB) error {
	// DuckDB çš„ FTS æ‰©å±•ä½¿ç”¨ PRAGMA create_fts_index åˆ›å»ºç´¢å¼•
	// è¯­æ³•ï¼šPRAGMA create_fts_index('table_name', 'id_column', 'text_column1', 'text_column2', ...)
	// åŒæ—¶ç´¢å¼• content å’Œ content_tokensï¼ˆsego åˆ†è¯ç»“æœï¼‰å­—æ®µ
	createFTSSQL := `PRAGMA create_fts_index('documents', 'id', 'content', 'content_tokens');`
	_, err := db.Exec(createFTSSQL)
	if err != nil {
		// å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
		if strings.Contains(err.Error(), "already exists") || strings.Contains(err.Error(), "duplicate") {
			logrus.Info("FTS index already exists")
			return nil
		}
		return fmt.Errorf("failed to create FTS index: %w", err)
	}

	logrus.Info("DuckDB FTS index created successfully with sego tokenization support")
	return nil
}

// tokenizeWithSego ä½¿ç”¨ sego å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œè¿”å›ç”¨ç©ºæ ¼åˆ†éš”çš„è¯
func tokenizeWithSego(text string) string {
	return sego.Tokenize(text)
}

// createDuckDBVectorIndex åˆ›å»º DuckDB å‘é‡ç´¢å¼•
func createDuckDBVectorIndex(db *sql.DB) error {
	// ä½¿ç”¨ DuckDB çš„ VSS æ‰©å±•åˆ›å»º HNSW å‘é‡ç´¢å¼•
	// æ³¨æ„ï¼šéœ€è¦ç¡®ä¿ embedding åˆ—å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
	createVectorIndexSQL := `
	CREATE INDEX IF NOT EXISTS documents_embedding_idx 
	ON documents USING hnsw (embedding);
	`
	_, err := db.Exec(createVectorIndexSQL)
	if err != nil {
		// å¦‚æœç´¢å¼•å·²å­˜åœ¨æˆ–åˆ—ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Šä½†ä¸å¤±è´¥
		if strings.Contains(err.Error(), "already exists") {
			logrus.Info("Vector index already exists")
			return nil
		}
		// å¦‚æœ embedding åˆ—ä¸å­˜åœ¨ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼ˆå› ä¸ºå®ƒæ˜¯å¯é€‰çš„ï¼‰
		if strings.Contains(err.Error(), "does not exist") || strings.Contains(err.Error(), "column") {
			logrus.Warn("Embedding column may not exist yet, vector index will be created when needed")
			return nil
		}
		return fmt.Errorf("failed to create vector index: %w", err)
	}

	logrus.Info("DuckDB vector index created successfully")
	return nil
}

// getDBInfo è·å–æ•°æ®åº“ä¿¡æ¯
func getDBInfo(c *gin.Context) {
	c.JSON(http.StatusOK, gin.H{
		"name": "browser-db",
		"path": os.Getenv("DB_PATH"),
	})
}

// getCollections è·å–æ‰€æœ‰é›†åˆ
func getCollections(c *gin.Context) {
	query := `SELECT DISTINCT collection_name FROM documents`
	rows, err := sqlDB.Query(query)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}
	defer rows.Close()

	var collections []string
	for rows.Next() {
		var name string
		if err := rows.Scan(&name); err != nil {
			continue
		}
		collections = append(collections, name)
	}

	collectionInfos := make([]CollectionInfo, len(collections))
	for i, name := range collections {
		collectionInfos[i] = CollectionInfo{
			Name:   name,
			Schema: make(map[string]interface{}),
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"collections": collectionInfos,
	})
}

// getCollection è·å–é›†åˆä¿¡æ¯
func getCollection(c *gin.Context) {
	name := c.Param("name")

	// æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
	var count int64
	query := `SELECT COUNT(*) FROM documents WHERE collection_name = ?`
	if err := sqlDB.QueryRow(query, name).Scan(&count); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"name":   name,
		"exists": count > 0,
		"count":  count,
	})
}

// getDocuments è·å–é›†åˆä¸­çš„æ‰€æœ‰æ–‡æ¡£
func getDocuments(c *gin.Context) {
	name := c.Param("name")
	limitStr := c.DefaultQuery("limit", "100")
	skipStr := c.DefaultQuery("skip", "0")
	tagFilter := c.Query("tag")

	limit, _ := strconv.Atoi(limitStr)
	skip, _ := strconv.Atoi(skipStr)

	logrus.WithFields(logrus.Fields{
		"collection": name,
		"limit":      limit,
		"skip":       skip,
		"tag":        tagFilter,
	}).Info("ğŸ“„ getDocuments")

	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(sqlDB, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check embedding column, assuming it exists")
		hasEmbedding = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ£€æŸ¥ content åˆ—æ˜¯å¦å­˜åœ¨
	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ„å»ºæŸ¥è¯¢ - æ ¹æ® embedding å’Œ content åˆ—æ˜¯å¦å­˜åœ¨åŠ¨æ€æ„å»º
	var baseQuery string
	if hasEmbedding && hasContent {
		baseQuery = `SELECT id, collection_name, data, embedding, content, created_at, updated_at FROM documents WHERE collection_name = ?`
	} else if hasEmbedding && !hasContent {
		baseQuery = `SELECT id, collection_name, data, embedding, NULL as content, created_at, updated_at FROM documents WHERE collection_name = ?`
	} else if !hasEmbedding && hasContent {
		baseQuery = `SELECT id, collection_name, data, NULL as embedding, content, created_at, updated_at FROM documents WHERE collection_name = ?`
	} else {
		baseQuery = `SELECT id, collection_name, data, NULL as embedding, NULL as content, created_at, updated_at FROM documents WHERE collection_name = ?`
	}
	args := []interface{}{name}

	if tagFilter != "" {
		// DuckDB æ”¯æŒ JSON å‡½æ•°
		baseQuery += ` AND json_extract(data, '$.tags') LIKE ?`
		args = append(args, "%"+tagFilter+"%")
	}

	// è·å–æ€»æ•°
	countQuery := `SELECT COUNT(*) FROM documents WHERE collection_name = ?`
	countArgs := []interface{}{name}
	if tagFilter != "" {
		countQuery += ` AND json_extract(data, '$.tags') LIKE ?`
		countArgs = append(countArgs, "%"+tagFilter+"%")
	}

	var total int64
	if err := sqlDB.QueryRow(countQuery, countArgs...).Scan(&total); err != nil {
		logrus.WithError(err).Error("âŒ Failed to count documents")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// åˆ†é¡µæŸ¥è¯¢
	query := baseQuery + ` ORDER BY created_at DESC LIMIT ? OFFSET ?`
	args = append(args, limit, skip)

	rows, err := sqlDB.Query(query, args...)
	if err != nil {
		logrus.WithError(err).Error("âŒ Failed to get documents")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}
	defer rows.Close()

	var docs []Document
	for rows.Next() {
		var doc Document
		var embeddingNull sql.NullString
		var contentNull sql.NullString
		if err := rows.Scan(&doc.ID, &doc.CollectionName, &doc.Data, &embeddingNull, &contentNull, &doc.CreatedAt, &doc.UpdatedAt); err != nil {
			logrus.WithError(err).Warn("Failed to scan document")
			continue
		}
		if embeddingNull.Valid {
			doc.Embedding = embeddingNull.String
		}
		if contentNull.Valid {
			doc.Content = contentNull.String
		}
		docs = append(docs, doc)
	}

	logrus.WithFields(logrus.Fields{
		"returned": len(docs),
		"total":    total,
		"skip":     skip,
		"limit":    limit,
	}).Info("ğŸ“„ Returning documents")

	response := make([]DocumentResponse, len(docs))
	for i, doc := range docs {
		var data map[string]interface{}
		if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			data = make(map[string]interface{})
		}
		response[i] = DocumentResponse{
			ID:   doc.ID,
			Data: data,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"documents": response,
		"total":     total,
		"skip":      skip,
		"limit":     limit,
	})
}

// getDocument è·å–å•ä¸ªæ–‡æ¡£
func getDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(sqlDB, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check embedding column, assuming it exists")
		hasEmbedding = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ£€æŸ¥ content åˆ—æ˜¯å¦å­˜åœ¨
	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	var doc Document
	var embeddingNull sql.NullString
	var contentNull sql.NullString
	var query string
	if hasEmbedding && hasContent {
		query = `SELECT id, collection_name, data, embedding, content, created_at, updated_at FROM documents WHERE collection_name = ? AND id = ?`
	} else if hasEmbedding && !hasContent {
		query = `SELECT id, collection_name, data, embedding, NULL as content, created_at, updated_at FROM documents WHERE collection_name = ? AND id = ?`
	} else if !hasEmbedding && hasContent {
		query = `SELECT id, collection_name, data, NULL as embedding, content, created_at, updated_at FROM documents WHERE collection_name = ? AND id = ?`
	} else {
		query = `SELECT id, collection_name, data, NULL as embedding, NULL as content, created_at, updated_at FROM documents WHERE collection_name = ? AND id = ?`
	}
	err = sqlDB.QueryRow(query, name, id).Scan(&doc.ID, &doc.CollectionName, &doc.Data, &embeddingNull, &contentNull, &doc.CreatedAt, &doc.UpdatedAt)
	if contentNull.Valid {
		doc.Content = contentNull.String
	}
	if err != nil {
		if err == sql.ErrNoRows {
			c.JSON(http.StatusNotFound, ErrorResponse{Error: "Document not found"})
		} else {
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		}
		return
	}
	if embeddingNull.Valid {
		doc.Embedding = embeddingNull.String
	}

	var data map[string]interface{}
	if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, DocumentResponse{
		ID:   doc.ID,
		Data: data,
	})
}

// createDocument åˆ›å»ºæ–‡æ¡£
func createDocument(c *gin.Context) {
	name := c.Param("name")

	var data map[string]interface{}
	if err := c.ShouldBindJSON(&data); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// ç”Ÿæˆ IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
	id, ok := data["id"].(string)
	if !ok || id == "" {
		id = generateID()
		data["id"] = id
	}

	// å°†æ•°æ®åºåˆ—åŒ–ä¸º JSON
	dataJSON, err := json.Marshal(data)
	if err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// æå–æ–‡æœ¬å†…å®¹ç”¨äºå…¨æ–‡æœç´¢
	content := extractTextFromData(string(dataJSON))
	// ä½¿ç”¨ sego å¯¹å†…å®¹è¿›è¡Œåˆ†è¯
	contentTokens := tokenizeWithSego(content)

	// æå– embeddingï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	embeddingStr := ""
	if embeddingField, ok := data["embedding"]; ok {
		embeddingJSON, err := json.Marshal(embeddingField)
		if err == nil {
			embeddingStr = string(embeddingJSON)
		}
	}

	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(sqlDB, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check embedding column, assuming it exists")
		hasEmbedding = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ£€æŸ¥ content åˆ—æ˜¯å¦å­˜åœ¨
	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ£€æŸ¥ content_tokens åˆ—æ˜¯å¦å­˜åœ¨
	hasContentTokens, err := columnExists(sqlDB, "documents", "content_tokens")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content_tokens column, assuming it exists")
		hasContentTokens = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ’å…¥æ–‡æ¡£ - æ ¹æ® embeddingã€content å’Œ content_tokens åˆ—æ˜¯å¦å­˜åœ¨åŠ¨æ€æ„å»º
	var insertQuery string
	if hasEmbedding && hasContent && hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, embedding, content, content_tokens, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), embeddingStr, content, contentTokens)
	} else if hasEmbedding && hasContent && !hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, embedding, content, created_at, updated_at) VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), embeddingStr, content)
	} else if hasEmbedding && !hasContent && hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, embedding, content_tokens, created_at, updated_at) VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), embeddingStr, contentTokens)
	} else if hasEmbedding && !hasContent && !hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, embedding, created_at, updated_at) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), embeddingStr)
	} else if !hasEmbedding && hasContent && hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, content, content_tokens, created_at, updated_at) VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), content, contentTokens)
	} else if !hasEmbedding && hasContent && !hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, content, created_at, updated_at) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), content)
	} else if !hasEmbedding && !hasContent && hasContentTokens {
		insertQuery = `INSERT INTO documents (id, collection_name, data, content_tokens, created_at, updated_at) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON), contentTokens)
	} else {
		insertQuery = `INSERT INTO documents (id, collection_name, data, created_at, updated_at) VALUES (?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`
		_, err = sqlDB.Exec(insertQuery, id, name, string(dataJSON))
	}
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤

	c.JSON(http.StatusCreated, DocumentResponse{
		ID:   id,
		Data: data,
	})
}

// updateDocument æ›´æ–°æ–‡æ¡£
func updateDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(sqlDB, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check embedding column, assuming it exists")
		hasEmbedding = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ£€æŸ¥ content åˆ—æ˜¯å¦å­˜åœ¨
	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// è·å–ç°æœ‰æ–‡æ¡£
	var doc Document
	var embeddingNull sql.NullString
	var contentNull sql.NullString
	var query string
	if hasEmbedding && hasContent {
		query = `SELECT id, collection_name, data, embedding, content FROM documents WHERE collection_name = ? AND id = ?`
	} else if hasEmbedding && !hasContent {
		query = `SELECT id, collection_name, data, embedding, NULL as content FROM documents WHERE collection_name = ? AND id = ?`
	} else if !hasEmbedding && hasContent {
		query = `SELECT id, collection_name, data, NULL as embedding, content FROM documents WHERE collection_name = ? AND id = ?`
	} else {
		query = `SELECT id, collection_name, data, NULL as embedding, NULL as content FROM documents WHERE collection_name = ? AND id = ?`
	}
	err = sqlDB.QueryRow(query, name, id).Scan(&doc.ID, &doc.CollectionName, &doc.Data, &embeddingNull, &contentNull)
	if contentNull.Valid {
		doc.Content = contentNull.String
	}
	if err != nil {
		if err == sql.ErrNoRows {
			c.JSON(http.StatusNotFound, ErrorResponse{Error: "Document not found"})
		} else {
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		}
		return
	}
	if embeddingNull.Valid {
		doc.Embedding = embeddingNull.String
	}

	var updates map[string]interface{}
	if err := c.ShouldBindJSON(&updates); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	// è§£æç°æœ‰æ•°æ®
	var data map[string]interface{}
	if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// åˆå¹¶æ›´æ–°
	for k, v := range updates {
		data[k] = v
	}

	// ç¡®ä¿ ID ä¸å˜
	data["id"] = id

	// åºåˆ—åŒ–å› JSON
	dataJSON, err := json.Marshal(data)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// æå–æ–‡æœ¬å†…å®¹ç”¨äºå…¨æ–‡æœç´¢
	content := extractTextFromData(string(dataJSON))
	// ä½¿ç”¨ sego å¯¹å†…å®¹è¿›è¡Œåˆ†è¯
	contentTokens := tokenizeWithSego(content)

	// æå– embeddingï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	embeddingStr := ""
	if embeddingField, ok := data["embedding"]; ok {
		embeddingJSON, err := json.Marshal(embeddingField)
		if err == nil {
			embeddingStr = string(embeddingJSON)
		}
	}

	// æ£€æŸ¥ content_tokens åˆ—æ˜¯å¦å­˜åœ¨
	hasContentTokens, err := columnExists(sqlDB, "documents", "content_tokens")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content_tokens column, assuming it exists")
		hasContentTokens = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// æ›´æ–°æ–‡æ¡£ - æ ¹æ® embeddingã€content å’Œ content_tokens åˆ—æ˜¯å¦å­˜åœ¨åŠ¨æ€æ„å»º
	var updateQuery string
	if hasEmbedding && hasContent && hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, embedding = ?, content = ?, content_tokens = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), embeddingStr, content, contentTokens, name, id)
	} else if hasEmbedding && hasContent && !hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, embedding = ?, content = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), embeddingStr, content, name, id)
	} else if hasEmbedding && !hasContent && hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, embedding = ?, content_tokens = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), embeddingStr, contentTokens, name, id)
	} else if hasEmbedding && !hasContent && !hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, embedding = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), embeddingStr, name, id)
	} else if !hasEmbedding && hasContent && hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, content = ?, content_tokens = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), content, contentTokens, name, id)
	} else if !hasEmbedding && hasContent && !hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, content = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), content, name, id)
	} else if !hasEmbedding && !hasContent && hasContentTokens {
		updateQuery = `UPDATE documents SET data = ?, content_tokens = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), contentTokens, name, id)
	} else {
		updateQuery = `UPDATE documents SET data = ?, updated_at = CURRENT_TIMESTAMP WHERE collection_name = ? AND id = ?`
		_, err = sqlDB.Exec(updateQuery, string(dataJSON), name, id)
	}
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤

	c.JSON(http.StatusOK, DocumentResponse{
		ID:   doc.ID,
		Data: data,
	})
}

// deleteDocument åˆ é™¤æ–‡æ¡£
func deleteDocument(c *gin.Context) {
	name := c.Param("name")
	id := c.Param("id")

	deleteQuery := `DELETE FROM documents WHERE collection_name = ? AND id = ?`
	_, err := sqlDB.Exec(deleteQuery, name, id)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	// DuckDB çš„ FTS ç´¢å¼•ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤

	c.JSON(http.StatusOK, gin.H{"message": "Document deleted"})
}

// fulltextSearch å…¨æ–‡æœç´¢
func fulltextSearch(c *gin.Context) {
	name := c.Param("name")

	var req FulltextSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	start := time.Now()

	// æ£€æŸ¥ content åˆ—æ˜¯å¦å­˜åœ¨
	hasContent, err := columnExists(sqlDB, "documents", "content")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content column, assuming it exists")
		hasContent = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// å¦‚æœ content åˆ—ä¸å­˜åœ¨ï¼Œä½¿ç”¨ data åˆ—è¿›è¡Œæœç´¢
	if !hasContent {
		logrus.Warn("Content column does not exist, using data column for search")
		query := `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND data LIKE ?
		LIMIT ?
		`
		searchPattern := "%" + req.Query + "%"
		rows, err := sqlDB.Query(query, name, searchPattern, req.Limit)
		if err != nil {
			logrus.WithError(err).Error("Fulltext search failed")
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
			return
		}
		defer rows.Close()

		var results []gin.H
		for rows.Next() {
			var docID, collectionName, dataJSON string
			var score float64
			if err := rows.Scan(&docID, &collectionName, &dataJSON, &score); err != nil {
				logrus.WithError(err).Error("Failed to scan row")
				continue
			}

			// æ£€æŸ¥é˜ˆå€¼
			if req.Threshold > 0 && score < req.Threshold {
				continue
			}

			var data map[string]interface{}
			if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
				logrus.WithError(err).Warn("Failed to unmarshal document data")
				continue
			}

			results = append(results, gin.H{
				"document": DocumentResponse{
					ID:   docID,
					Data: data,
				},
				"score": score,
			})
		}

		took := time.Since(start).Milliseconds()

		c.JSON(http.StatusOK, gin.H{
			"results": results,
			"query":   req.Query,
			"took":    took,
		})
		return
	}

	// æ£€æŸ¥ FTS ç´¢å¼•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•åˆ›å»º
	var indexExists bool
	// DuckDB ä½¿ç”¨ä¸åŒçš„ç³»ç»Ÿè¡¨æ¥æ£€æŸ¥ç´¢å¼•
	checkSQL := `SELECT COUNT(*) FROM pragma_table_info('documents') WHERE name = 'content'`
	var count int
	if err := sqlDB.QueryRow(checkSQL).Scan(&count); err == nil && count > 0 {
		// å°è¯•æŸ¥è¯¢ FTS ç´¢å¼•ï¼ˆDuckDB FTS ç´¢å¼•å¯èƒ½ä¸ä¼šåœ¨å¸¸è§„ç´¢å¼•è¡¨ä¸­æ˜¾ç¤ºï¼‰
		// æˆ‘ä»¬é€šè¿‡å°è¯•åˆ›å»ºç´¢å¼•æ¥åˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨
		indexExists = false // å…ˆå‡è®¾ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»ºæ—¶ä¼šå¤„ç†å·²å­˜åœ¨çš„æƒ…å†µ
	}

	if !indexExists {
		logrus.Warn("FTS index does not exist, attempting to create it")
		if err := createDuckDBFTSIndex(sqlDB); err != nil {
			logrus.WithError(err).Error("Failed to create FTS index")
			// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­ä½¿ç”¨ LIKE æŸ¥è¯¢ä½œä¸ºå›é€€
		}
	}

	// ä½¿ç”¨ sego å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†è¯
	queryTokens := tokenizeWithSego(req.Query)

	// æ£€æŸ¥ content_tokens åˆ—æ˜¯å¦å­˜åœ¨
	hasContentTokens, err := columnExists(sqlDB, "documents", "content_tokens")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check content_tokens column, assuming it exists")
		hasContentTokens = true // é»˜è®¤å‡è®¾å­˜åœ¨ï¼Œä¿æŒå‘åå…¼å®¹
	}

	// ä½¿ç”¨ DuckDB FTS è¿›è¡Œå…¨æ–‡æœç´¢
	// ä¼˜å…ˆä½¿ç”¨ content_tokens å­—æ®µè¿›è¡Œæœç´¢ï¼ˆsego åˆ†è¯ç»“æœï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ content å­—æ®µ
	var query string
	var searchText string
	if hasContentTokens && queryTokens != "" {
		// ä½¿ç”¨åˆ†è¯ç»“æœæœç´¢ content_tokens å­—æ®µ
		query = `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND content_tokens MATCH ?
		LIMIT ?
		`
		searchText = queryTokens
	} else {
		// å›é€€åˆ°åŸå§‹ content å­—æ®µæœç´¢
		query = `
		SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
		FROM documents
		WHERE collection_name = ? 
		  AND content MATCH ?
		LIMIT ?
		`
		searchText = req.Query
	}

	rows, err := sqlDB.Query(query, name, searchText, req.Limit)
	if err != nil {
		// å¦‚æœ FTS æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨ LIKE æŸ¥è¯¢ä½œä¸ºå›é€€
		logrus.WithError(err).Warn("FTS query failed, using LIKE query as fallback")
		// å¦‚æœ content_tokens å­˜åœ¨ï¼Œä¼˜å…ˆåœ¨ content_tokens ä¸­æœç´¢
		if hasContentTokens && queryTokens != "" {
			query = `
			SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
			FROM documents
			WHERE collection_name = ? 
			  AND content_tokens LIKE ?
			LIMIT ?
			`
			searchPattern := "%" + queryTokens + "%"
			rows, err = sqlDB.Query(query, name, searchPattern, req.Limit)
		} else {
			query = `
			SELECT id, collection_name, data, CAST(1.0 AS DOUBLE) as score
			FROM documents
			WHERE collection_name = ? 
			  AND content LIKE ?
			LIMIT ?
			`
			searchPattern := "%" + req.Query + "%"
			rows, err = sqlDB.Query(query, name, searchPattern, req.Limit)
		}
		if err != nil {
			logrus.WithError(err).Error("Fulltext search failed")
			c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
			return
		}
	}
	defer rows.Close()

	var results []gin.H
	for rows.Next() {
		var docID, collectionName, dataJSON string
		var score float64
		if err := rows.Scan(&docID, &collectionName, &dataJSON, &score); err != nil {
			logrus.WithError(err).Error("Failed to scan row")
			continue
		}

		// æ£€æŸ¥é˜ˆå€¼ï¼ˆæ³¨æ„ï¼šDuckDB FTS çš„åˆ†æ•°å¯èƒ½ä¸åŒï¼Œè¿™é‡Œä½¿ç”¨ç®€å•çš„è¿‡æ»¤ï¼‰
		if req.Threshold > 0 && score < req.Threshold {
			continue
		}

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
			logrus.WithError(err).Warn("Failed to unmarshal document data")
			continue
		}

		results = append(results, gin.H{
			"document": DocumentResponse{
				ID:   docID,
				Data: data,
			},
			"score": score,
		})
	}

	took := time.Since(start).Milliseconds()

	c.JSON(http.StatusOK, gin.H{
		"results": results,
		"query":   req.Query,
		"took":    took,
	})
}

// vectorSearch å‘é‡æœç´¢
func vectorSearch(c *gin.Context) {
	name := c.Param("name")

	bodyBytes, _ := io.ReadAll(c.Request.Body)
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	var req VectorSearchRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		logrus.WithError(err).Error("Failed to bind JSON")
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: fmt.Sprintf("Invalid request format: %v", err),
		})
		return
	}

	logrus.WithFields(logrus.Fields{
		"collection":   name,
		"hasQuery":     len(req.Query) > 0,
		"hasQueryText": req.QueryText != "",
		"queryText":    req.QueryText,
		"limit":        req.Limit,
		"field":        req.Field,
	}).Info("Vector search request")

	// å¦‚æœæä¾›äº†æ–‡æœ¬æŸ¥è¯¢ï¼Œç”Ÿæˆ embedding
	var queryVector []float64
	if req.QueryText != "" {
		logrus.WithField("queryText", req.QueryText).Info("ğŸ”„ Generating embedding from text")
		embedding, err := generateEmbeddingFromText(req.QueryText)
		if err != nil {
			logrus.WithError(err).Error("âŒ Failed to generate embedding from text")
			c.JSON(http.StatusBadRequest, ErrorResponse{
				Error: fmt.Sprintf("Failed to generate embedding from text: %v", err),
			})
			return
		}
		queryVector = embedding
		logrus.WithFields(logrus.Fields{
			"dimension": len(queryVector),
			"first3":    queryVector[:min(3, len(queryVector))],
		}).Info("âœ… Generated embedding")
	} else if len(req.Query) > 0 {
		queryVector = req.Query
		logrus.WithField("dimension", len(queryVector)).Info("Using provided vector")
	} else {
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: "Either 'query' (vector) or 'query_text' (text) must be provided",
		})
		return
	}

	if req.Limit <= 0 {
		req.Limit = 10
	}

	if req.Field == "" {
		req.Field = "embedding"
	}

	// ç”±äº embedding å­˜å‚¨ä¸º JSON å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬ä½¿ç”¨å†…å­˜è®¡ç®—è¿›è¡Œå‘é‡æœç´¢
	// æœªæ¥å¯ä»¥ä¼˜åŒ–ä¸ºç›´æ¥åœ¨ DuckDB ä¸­å­˜å‚¨æ•°ç»„ç±»å‹å¹¶ä½¿ç”¨ VSS æ‰©å±•
	// ç›®å‰ä½¿ç”¨å›é€€æ–¹æ¡ˆï¼ˆå†…å­˜è®¡ç®—ï¼‰
	vectorSearchFallback(c, name, req, queryVector)
}

// vectorSearchFallback å‘é‡æœç´¢çš„å›é€€æ–¹æ¡ˆï¼ˆå†…å­˜è®¡ç®—ï¼‰
func vectorSearchFallback(c *gin.Context, name string, req VectorSearchRequest, queryVector []float64) {
	start := time.Now()

	// è·å–é›†åˆä¸­çš„æ‰€æœ‰æ–‡æ¡£
	var docs []Document
	if err := gormDB.Where("collection_name = ?", name).Find(&docs).Error; err != nil {
		logrus.WithError(err).Error("Failed to get documents for vector search")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	type VectorResult struct {
		Document DocumentResponse
		Score    float64
	}

	var results []VectorResult

	// éå†æ–‡æ¡£ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
	for _, doc := range docs {
		var data map[string]interface{}
		if err := json.Unmarshal([]byte(doc.Data), &data); err != nil {
			continue
		}

		// è·å–æ–‡æ¡£çš„ embedding
		embeddingField, ok := data[req.Field]
		if !ok {
			continue
		}

		// è½¬æ¢ embedding ä¸º []float64
		var docVector []float64
		switch v := embeddingField.(type) {
		case []interface{}:
			docVector = make([]float64, len(v))
			for i, val := range v {
				if f, ok := val.(float64); ok {
					docVector[i] = f
				} else if f, ok := val.(float32); ok {
					docVector[i] = float64(f)
				} else {
					docVector = nil
					break
				}
			}
		case []float64:
			docVector = v
		default:
			continue
		}

		if docVector == nil || len(docVector) == 0 {
			continue
		}

		// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
		similarity := cosineSimilarity(queryVector, docVector)

		// åº”ç”¨é˜ˆå€¼è¿‡æ»¤ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
		if req.Threshold > 0 && similarity < req.Threshold {
			continue
		}

		results = append(results, VectorResult{
			Document: DocumentResponse{
				ID:   doc.ID,
				Data: data,
			},
			Score: similarity,
		})
	}

	// æŒ‰ç›¸ä¼¼åº¦æ’åºï¼ˆé™åºï¼‰
	for i := 0; i < len(results)-1; i++ {
		for j := i + 1; j < len(results); j++ {
			if results[i].Score < results[j].Score {
				results[i], results[j] = results[j], results[i]
			}
		}
	}

	// é™åˆ¶ç»“æœæ•°é‡
	if len(results) > req.Limit {
		results = results[:req.Limit]
	}

	took := time.Since(start).Milliseconds()

	// è½¬æ¢ä¸ºå“åº”æ ¼å¼
	responseResults := make([]gin.H, len(results))
	for i, r := range results {
		responseResults[i] = gin.H{
			"document": r.Document,
			"score":    r.Score,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"results": responseResults,
		"query":   req.QueryText,
		"took":    took,
	})
}

// generateID ç”Ÿæˆæ–‡æ¡£ ID
func generateID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

// DuckDB çš„ FTS ç´¢å¼•æ˜¯è‡ªåŠ¨ç»´æŠ¤çš„ï¼Œæ— éœ€æ‰‹åŠ¨é‡æ–°ç´¢å¼•

// extractTextFromData ä» JSON æ•°æ®ä¸­æå–æ–‡æœ¬å†…å®¹
func extractTextFromData(dataJSON string) string {
	var data map[string]interface{}
	if err := json.Unmarshal([]byte(dataJSON), &data); err != nil {
		return ""
	}

	var parts []string
	for k, v := range data {
		if k == "id" || k == "_rev" || k == "embedding" {
			continue
		}
		if str, ok := v.(string); ok {
			parts = append(parts, str)
		} else if arr, ok := v.([]interface{}); ok {
			// å¤„ç†æ•°ç»„å­—æ®µï¼ˆå¦‚ tagsï¼‰
			for _, item := range arr {
				if str, ok := item.(string); ok {
					parts = append(parts, str)
				}
			}
		} else {
			parts = append(parts, fmt.Sprintf("%v", v))
		}
	}
	return strings.Join(parts, " ")
}

// DuckDB çš„ FTS ç´¢å¼•æ˜¯è‡ªåŠ¨ç»´æŠ¤çš„ï¼Œæ— éœ€æ‰‹åŠ¨é‡æ–°ç´¢å¼•

// DashScope API ç»“æ„
type DashScopeEmbeddingRequest struct {
	Model string         `json:"model"`
	Input DashScopeInput `json:"input"`
}

type DashScopeInput struct {
	Texts []string `json:"texts"`
}

type DashScopeEmbeddingResponse struct {
	Output DashScopeOutput `json:"output"`
}

type DashScopeOutput struct {
	Embeddings []DashScopeEmbedding `json:"embeddings"`
}

type DashScopeEmbedding struct {
	Embedding []float32 `json:"embedding"`
}

// generateEmbeddingFromText ä½¿ç”¨ DashScope API ä»æ–‡æœ¬ç”Ÿæˆ embedding
func generateEmbeddingFromText(text string) ([]float64, error) {
	apiKey := os.Getenv("DASHSCOPE_API_KEY")
	if apiKey == "" {
		return nil, fmt.Errorf("DASHSCOPE_API_KEY environment variable is not set")
	}

	url := "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding"

	reqBody := DashScopeEmbeddingRequest{
		Model: "text-embedding-v4",
		Input: DashScopeInput{
			Texts: []string{text},
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to send request: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("API request failed with status %d: %s", resp.StatusCode, string(body))
	}

	var apiResp DashScopeEmbeddingResponse
	if err := json.Unmarshal(body, &apiResp); err != nil {
		return nil, fmt.Errorf("failed to unmarshal response: %w", err)
	}

	if len(apiResp.Output.Embeddings) == 0 {
		return nil, fmt.Errorf("no embedding returned")
	}

	embedding := apiResp.Output.Embeddings[0].Embedding
	result := make([]float64, len(embedding))
	for i, v := range embedding {
		result[i] = float64(v)
	}

	return result, nil
}

// min è¾…åŠ©å‡½æ•°
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// cosineSimilarity è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
func cosineSimilarity(a, b []float64) float64 {
	if len(a) != len(b) {
		return 0.0
	}

	var dotProduct, normA, normB float64
	for i := 0; i < len(a); i++ {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0.0
	}

	return dotProduct / (sqrt(normA) * sqrt(normB))
}

// sqrt è®¡ç®—å¹³æ–¹æ ¹ï¼ˆä½¿ç”¨æ ‡å‡†åº“ï¼‰
func sqrt(x float64) float64 {
	return math.Sqrt(x)
}

// ========================================
// å›¾æ•°æ®åº“ API å¤„ç†å‡½æ•°
// ========================================

type GraphLinkRequest struct {
	From     string `json:"from" binding:"required"`
	Relation string `json:"relation" binding:"required"`
	To       string `json:"to" binding:"required"`
}

type GraphPathRequest struct {
	From      string   `json:"from" binding:"required"`
	To        string   `json:"to" binding:"required"`
	MaxDepth  int      `json:"max_depth"`
	Relations []string `json:"relations,omitempty"`
}

type GraphQueryRequest struct {
	Query string `json:"query" binding:"required"`
}

// graphLink åˆ›å»ºå›¾å…³ç³»é“¾æ¥
func graphLink(c *gin.Context) {
	var req GraphLinkRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	if err := graphDB.Link(dbContext, req.From, req.Relation, req.To); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"message":  "Link created successfully",
		"from":     req.From,
		"relation": req.Relation,
		"to":       req.To,
	})
}

// graphUnlink åˆ é™¤å›¾å…³ç³»é“¾æ¥
func graphUnlink(c *gin.Context) {
	var req GraphLinkRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	if err := graphDB.Unlink(dbContext, req.From, req.Relation, req.To); err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"message":  "Link deleted successfully",
		"from":     req.From,
		"relation": req.Relation,
		"to":       req.To,
	})
}

// graphNeighbors è·å–èŠ‚ç‚¹çš„é‚»å±…
func graphNeighbors(c *gin.Context) {
	nodeID := c.Param("nodeId")
	relation := c.DefaultQuery("relation", "")

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	neighbors, err := graphDB.GetNeighbors(dbContext, nodeID, relation)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"node_id":   nodeID,
		"relation":  relation,
		"neighbors": neighbors,
	})
}

// graphPath æŸ¥æ‰¾ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è·¯å¾„
func graphPath(c *gin.Context) {
	var req GraphPathRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if req.MaxDepth == 0 {
		req.MaxDepth = 5
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	var paths [][]string
	var err error

	// Cayley é©±åŠ¨çš„ FindPath åªæ¥å—å•ä¸ª predicateï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
	predicate := ""
	if len(req.Relations) > 0 {
		predicate = req.Relations[0]
	}

	paths, err = graphDB.FindPath(dbContext, req.From, req.To, req.MaxDepth, predicate)
	if err != nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"from":  req.From,
		"to":    req.To,
		"paths": paths,
	})
}

// graphQuery æ‰§è¡Œå›¾æŸ¥è¯¢
func graphQuery(c *gin.Context) {
	var req GraphQueryRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, ErrorResponse{Error: err.Error()})
		return
	}

	if graphDB == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Graph database not available",
		})
		return
	}

	query := graphDB.Query()
	if query == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "Query builder not available",
		})
		return
	}

	logrus.WithField("query", req.Query).Info("ğŸ” è§£ææŸ¥è¯¢å­—ç¬¦ä¸²")

	// è§£æ V('nodeId')
	if !strings.HasPrefix(req.Query, "V(") {
		c.JSON(http.StatusBadRequest, ErrorResponse{
			Error: "æŸ¥è¯¢å¿…é¡»ä»¥ V('nodeId') å¼€å§‹",
		})
		return
	}

	// æå–èŠ‚ç‚¹ID
	var nodeID string
	var vEndIndex int

	nodeStart := strings.Index(req.Query, "('")
	if nodeStart == -1 {
		nodeStart = strings.Index(req.Query, "(\"")
		if nodeStart == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{
				Error: "æ— æ³•è§£æèŠ‚ç‚¹IDï¼Œæ ¼å¼åº”ä¸º V('nodeId') æˆ– V(\"nodeId\")",
			})
			return
		}
		relEnd := strings.Index(req.Query[nodeStart+2:], "\")")
		if relEnd == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{Error: "èŠ‚ç‚¹IDæ ¼å¼é”™è¯¯"})
			return
		}
		nodeID = req.Query[nodeStart+2 : nodeStart+2+relEnd]
		vEndIndex = nodeStart + 2 + relEnd + 2
	} else {
		relEnd := strings.Index(req.Query[nodeStart+2:], "')")
		if relEnd == -1 {
			c.JSON(http.StatusBadRequest, ErrorResponse{Error: "èŠ‚ç‚¹IDæ ¼å¼é”™è¯¯"})
			return
		}
		nodeID = req.Query[nodeStart+2 : nodeStart+2+relEnd]
		vEndIndex = nodeStart + 2 + relEnd + 2
	}

	logrus.WithField("node_id", nodeID).Info("ğŸ“Œ æå–èŠ‚ç‚¹ID")

	// åˆ›å»ºåŸºç¡€æŸ¥è¯¢
	queryImpl := query.V(nodeID)
	if queryImpl == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "åˆ›å»ºæŸ¥è¯¢å¤±è´¥",
		})
		return
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰ .Out() æˆ– .In()
	remainingQuery := ""
	if vEndIndex < len(req.Query) {
		remainingQuery = req.Query[vEndIndex:]
	}
	logrus.WithField("remaining_query", remainingQuery).Info("ğŸ“‹ å‰©ä½™æŸ¥è¯¢éƒ¨åˆ†")

	if strings.HasPrefix(remainingQuery, ".Out(") {
		relStart := strings.Index(remainingQuery, "('")
		if relStart == -1 {
			relStart = strings.Index(remainingQuery, "(\"")
			if relStart == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "æ— æ³•è§£æå…³ç³»åç§°"})
				return
			}
			relEnd := strings.Index(remainingQuery[relStart+2:], "\")")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (Out)")
			queryImpl = queryImpl.Out(relation)
		} else {
			relEnd := strings.Index(remainingQuery[relStart+2:], "')")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (Out)")
			queryImpl = queryImpl.Out(relation)
		}
	} else if strings.HasPrefix(remainingQuery, ".In(") {
		relStart := strings.Index(remainingQuery, "('")
		if relStart == -1 {
			relStart = strings.Index(remainingQuery, "(\"")
			if relStart == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "æ— æ³•è§£æå…³ç³»åç§°"})
				return
			}
			relEnd := strings.Index(remainingQuery[relStart+2:], "\")")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (In)")
			queryImpl = queryImpl.In(relation)
		} else {
			relEnd := strings.Index(remainingQuery[relStart+2:], "')")
			if relEnd == -1 {
				c.JSON(http.StatusBadRequest, ErrorResponse{Error: "å…³ç³»åç§°æ ¼å¼é”™è¯¯"})
				return
			}
			relation := remainingQuery[relStart+2 : relStart+2+relEnd]
			logrus.WithField("relation", relation).Info("ğŸ”— æå–å…³ç³» (In)")
			queryImpl = queryImpl.In(relation)
		}
	}

	if queryImpl == nil {
		c.JSON(http.StatusInternalServerError, ErrorResponse{
			Error: "æ„å»ºæŸ¥è¯¢å¤±è´¥",
		})
		return
	}

	// æ‰§è¡ŒæŸ¥è¯¢
	logrus.Info("ğŸš€ æ‰§è¡Œå›¾æŸ¥è¯¢...")
	queryResults, err := queryImpl.All(dbContext)
	if err != nil {
		logrus.WithError(err).Info("âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
		c.JSON(http.StatusInternalServerError, ErrorResponse{Error: err.Error()})
		return
	}

	logrus.WithField("count", len(queryResults)).Info("âœ… æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°ç»“æœ")

	// è½¬æ¢ç»“æœ
	results := make([]gin.H, len(queryResults))
	for i, r := range queryResults {
		results[i] = gin.H{
			"subject":   r.Subject,
			"predicate": r.Predicate,
			"object":    r.Object,
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"query":   req.Query,
		"results": results,
	})
}
