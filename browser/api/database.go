package main

import (
	"context"
	"database/sql"
	"fmt"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	cayley_driver "github.com/mozhou-tech/sqlite-ai-driver/pkg/cayley-driver"
	_ "github.com/mozhou-tech/sqlite-ai-driver/pkg/duckdb-driver"
	"github.com/sirupsen/logrus"
	"gorm.io/gorm"
)

var (
	gormDB       *gorm.DB
	sqlDB        *sql.DB
	graphDB      cayley_driver.Graph
	dbContext    context.Context
	embeddingDim int // embedding å‘é‡ç»´åº¦
)

// getEmbeddingDimension è·å– embedding å‘é‡ç»´åº¦
func getEmbeddingDimension() int {
	if embeddingDim > 0 {
		return embeddingDim
	}
	// ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ä¸º 1024 text-embedding-v4 çš„ç»´åº¦ï¼‰
	dimStr := os.Getenv("EMBEDDING_DIMENSION")
	if dimStr != "" {
		if dim, err := strconv.Atoi(dimStr); err == nil && dim > 0 {
			embeddingDim = dim
			return embeddingDim
		}
	}
	// é»˜è®¤ç»´åº¦ä¸º 1536
	embeddingDim = 1024
	return embeddingDim
}

// initDatabase åˆå§‹åŒ–æ•°æ®åº“
func initDatabase() error {

	dbPath := os.Getenv("DB_PATH")
	if dbPath == "" {
		dbPath = "./testdata/"
	}

	// ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(dbPath, 0755); err != nil {
		return fmt.Errorf("failed to create data directory: %w", err)
	}

	ctx := context.Background()
	dbContext = ctx

	// åˆå§‹åŒ– embedding ç»´åº¦
	dim := getEmbeddingDimension()
	logrus.WithField("embedding_dimension", dim).Info("Embedding dimension initialized")

	// åˆå§‹åŒ– DuckDB æ•°æ®åº“
	// ä½¿ç”¨ duckdb-driverï¼Œå®ƒä¼šè‡ªåŠ¨åŠ è½½æ‰©å±•å¹¶å¤„ç†è·¯å¾„æ˜ å°„
	duckDBPath := filepath.Join(dbPath, "index.db")
	absDBPath, err := filepath.Abs(duckDBPath)
	if err != nil {
		return fmt.Errorf("failed to get absolute path: %w", err)
	}
	logrus.WithField("db_path", absDBPath).Info("Database path")

	// ä½¿ç”¨ duckdb-driverï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ‰©å±•åŠ è½½å’Œè¯»å†™æ¨¡å¼
	// æ³¨æ„ï¼šduckdb-driver ä¼šå°†è·¯å¾„æ˜ å°„åˆ° ./data/indexing/index.db
	// ä½†è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç»å¯¹è·¯å¾„æ¥ä¿æŒåŸæœ‰çš„æ•°æ®åº“ä½ç½®
	sqlDB, err = sql.Open("duckdb", absDBPath)
	if err != nil {
		return fmt.Errorf("failed to open database: %w", err)
	}

	// è®¾ç½®è¿æ¥æ± å‚æ•°
	sqlDB.SetMaxIdleConns(10)
	sqlDB.SetMaxOpenConns(100)
	sqlDB.SetConnMaxLifetime(time.Hour)

	// ç¡®ä¿æ‰©å±•å·²åŠ è½½
	if err := ensureDuckDBExtensions(sqlDB); err != nil {
		logrus.WithError(err).Warn("Some DuckDB extensions may not be available")
	}

	// å¯ç”¨ HNSW å®éªŒæ€§æŒä¹…åŒ–åŠŸèƒ½
	if _, err := sqlDB.Exec("SET hnsw_enable_experimental_persistence = true"); err != nil {
		logrus.WithError(err).Warn("Failed to enable HNSW experimental persistence, vector index may not work in persistent database")
		logrus.Error("âŒ å‘é‡æœç´¢åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨ï¼šHNSW å®éªŒæ€§æŒä¹…åŒ–åŠŸèƒ½æœªå¯ç”¨")
	} else {
		logrus.Info("HNSW experimental persistence enabled")
	}

	// åˆ›å»ºè¡¨ï¼ˆä½¿ç”¨å›ºå®šç»´åº¦çš„å‘é‡ç±»å‹ä»¥æ”¯æŒ HNSW ç´¢å¼•ï¼‰
	createTableSQL := fmt.Sprintf(`
	CREATE TABLE IF NOT EXISTS documents (
		id VARCHAR(255) PRIMARY KEY,
		collection_name VARCHAR(255) NOT NULL,
		data TEXT,
		embedding FLOAT[%d],
		content TEXT,
		content_tokens TEXT,
		created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
		updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
	);
	CREATE INDEX IF NOT EXISTS idx_documents_collection ON documents(collection_name);
	`, dim)
	if _, err := sqlDB.Exec(createTableSQL); err != nil {
		return fmt.Errorf("failed to create documents table: %w", err)
	}

	// ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
	if err := ensureTableColumns(sqlDB); err != nil {
		logrus.WithError(err).Warn("Failed to ensure table columns, some features may not work")
	}

	// åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
	if err := createDuckDBFTSIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create FTS index, fulltext search may not work")
	} else {
		logrus.Info("DuckDB FTS index created successfully")
	}

	// åˆ›å»ºå‘é‡ç´¢å¼•
	if err := createDuckDBVectorIndex(sqlDB); err != nil {
		logrus.WithError(err).Error("Failed to create vector index, vector search may not work")
	} else {
		logrus.Info("DuckDB vector index created successfully")
	}

	// åˆå§‹åŒ–å›¾æ•°æ®åº“
	graphDBPath := "graph.db"
	graphDB, err = cayley_driver.NewGraphWithNamespace(dbPath, graphDBPath, "")
	if err != nil {
		if strings.Contains(err.Error(), "database is locked") || strings.Contains(err.Error(), "locked") {
			logrus.WithError(err).Error("å›¾æ•°æ®åº“è¢«é”å®šï¼Œå¯èƒ½æ˜¯å¦ä¸€ä¸ªè¿›ç¨‹æ­£åœ¨ä½¿ç”¨")
			logrus.Error("ğŸ’¡ æç¤º: å¯ä»¥å°è¯•è¿è¡Œ 'make clean-lock' æˆ– 'make force-clean' æ¥æ¸…ç†é”æ–‡ä»¶")
			logrus.Error("   æˆ–è€…æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹æ­£åœ¨ä½¿ç”¨æ•°æ®åº“")
			graphDB = nil
		} else {
			return fmt.Errorf("failed to create graph database: %w", err)
		}
	}

	logrus.Info("Database initialized successfully")
	return nil
}

// columnExists æ£€æŸ¥è¡¨ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šåˆ—
func columnExists(db *sql.DB, tableName, columnName string) (bool, error) {
	query := `SELECT COUNT(*) FROM pragma_table_info(?) WHERE name = ?`
	var count int
	err := db.QueryRow(query, tableName, columnName).Scan(&count)
	if err != nil {
		return false, err
	}
	return count > 0, nil
}

// ensureTableColumns ç¡®ä¿è¡¨ä¸­æœ‰å¿…è¦çš„åˆ—ï¼ˆç”¨äºè¡¨ç»“æ„è¿ç§»ï¼‰
func ensureTableColumns(db *sql.DB) error {
	requiredColumns := []struct {
		name string
		typ  string
	}{
		{"content", "TEXT"},
		{"content_tokens", "TEXT"},
		{"embedding", "FLOAT[1024]"},
	}

	for _, col := range requiredColumns {
		exists, err := columnExists(db, "documents", col.name)
		if err != nil {
			logrus.WithError(err).WithField("column", col.name).Warn("Failed to check column existence")
			continue
		}

		if !exists {
			logrus.WithField("column", col.name).Info("Adding missing column to documents table")
			alterSQL := fmt.Sprintf("ALTER TABLE documents ADD COLUMN %s %s", col.name, col.typ)
			if _, err := db.Exec(alterSQL); err != nil {
				if !strings.Contains(err.Error(), "already exists") && !strings.Contains(err.Error(), "duplicate") {
					logrus.WithError(err).WithField("column", col.name).Warn("Failed to add column")
					return fmt.Errorf("failed to add column %s: %w", col.name, err)
				}
			} else {
				logrus.WithField("column", col.name).Info("Column added successfully")
			}
		}
	}

	return nil
}

// ensureDuckDBExtensions ç¡®ä¿ DuckDB æ‰©å±•å·²åŠ è½½
func ensureDuckDBExtensions(db *sql.DB) error {
	var count int
	err := db.QueryRow("SELECT COUNT(*) FROM duckdb_extensions() WHERE loaded = true AND extension_name IN ('fts', 'vss')").Scan(&count)
	if err != nil {
		logrus.Warn("Failed to check extensions, attempting to load manually")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
		return nil
	}

	if count < 2 {
		logrus.Warn("Some extensions may not be loaded, attempting to load")
		_, _ = db.Exec("INSTALL fts; LOAD fts;")
		_, _ = db.Exec("INSTALL vss; LOAD vss;")
	}

	logrus.Info("DuckDB extensions verified")
	return nil
}

// createDuckDBFTSIndex åˆ›å»º DuckDB å…¨æ–‡æœç´¢ç´¢å¼•
func createDuckDBFTSIndex(db *sql.DB) error {
	createFTSSQL := `PRAGMA create_fts_index('documents', 'id', 'content', 'content_tokens');`
	_, err := db.Exec(createFTSSQL)
	if err != nil {
		if strings.Contains(err.Error(), "already exists") || strings.Contains(err.Error(), "duplicate") {
			logrus.Info("FTS index already exists")
			return nil
		}
		return fmt.Errorf("failed to create FTS index: %w", err)
	}

	logrus.Info("DuckDB FTS index created successfully with sego tokenization support")
	return nil
}

// getColumnType è·å–åˆ—çš„ç±»å‹
func getColumnType(db *sql.DB, tableName, columnName string) (string, error) {
	query := `SELECT type FROM pragma_table_info(?) WHERE name = ?`
	var colType string
	err := db.QueryRow(query, tableName, columnName).Scan(&colType)
	if err != nil {
		return "", err
	}
	return colType, nil
}

// createDuckDBVectorIndex åˆ›å»º DuckDB å‘é‡ç´¢å¼•
func createDuckDBVectorIndex(db *sql.DB) error {
	// æ£€æŸ¥ embedding åˆ—æ˜¯å¦å­˜åœ¨
	hasEmbedding, err := columnExists(db, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to check embedding column")
		hasEmbedding = false
	}

	if !hasEmbedding {
		logrus.Warn("embedding column does not exist, vector index will not be created")
		logrus.Error("âŒ å‘é‡æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šembedding åˆ—ä¸å­˜åœ¨")
		return nil
	}

	// æ£€æŸ¥åˆ—ç±»å‹æ˜¯å¦ä¸ºå›ºå®šç»´åº¦çš„ FLOAT[N]
	dim := getEmbeddingDimension()
	colType, err := getColumnType(db, "documents", "embedding")
	if err != nil {
		logrus.WithError(err).Warn("Failed to get embedding column type")
	} else {
		expectedType := fmt.Sprintf("FLOAT[%d]", dim)
		if colType != expectedType && colType != fmt.Sprintf("FLOAT(%d)", dim) {
			logrus.WithFields(logrus.Fields{
				"current_type":  colType,
				"expected_type": expectedType,
			}).Error("âŒ embedding åˆ—ç±»å‹ä¸æ­£ç¡®ï¼Œæ— æ³•åˆ›å»º HNSW ç´¢å¼•")
			logrus.Error("ğŸ’¡ æç¤º: HNSW ç´¢å¼•éœ€è¦å›ºå®šç»´åº¦çš„å‘é‡ç±»å‹ï¼ˆå¦‚ FLOAT[1024]ï¼‰")
			logrus.Error("   å¦‚æœè¡¨å·²å­˜åœ¨ï¼Œæ‚¨éœ€è¦ï¼š")
			logrus.Error("   1. å¤‡ä»½æ•°æ®")
			logrus.Error("   2. åˆ é™¤è¡¨å¹¶é‡æ–°åˆ›å»º")
			logrus.Error("   3. æˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡ EMBEDDING_DIMENSION æ¥åŒ¹é…ç°æœ‰åˆ—çš„ç±»å‹")
			return fmt.Errorf("embedding column type is %s, expected %s. Please recreate the table with the correct type", colType, expectedType)
		}
	}

	createVectorIndexSQL := `
	CREATE INDEX IF NOT EXISTS documents_embedding_idx 
	ON documents USING hnsw (embedding) WITH (metric = 'cosine');
	`
	_, err = db.Exec(createVectorIndexSQL)
	if err != nil {
		if strings.Contains(err.Error(), "already exists") {
			logrus.Info("Vector index already exists")
			return nil
		}
		if strings.Contains(err.Error(), "does not exist") || strings.Contains(err.Error(), "column") {
			logrus.Warn("Embedding column may not exist yet, vector index will be created when needed")
			return nil
		}
		if strings.Contains(err.Error(), "in-memory") || strings.Contains(err.Error(), "hnsw_enable_experimental_persistence") {
			logrus.WithError(err).Error("HNSW index persistence may not be enabled")
			logrus.Error("âŒ å‘é‡æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šHNSW å‘é‡ç´¢å¼•éœ€è¦å®éªŒæ€§æŒä¹…åŒ–åŠŸèƒ½")
			return nil
		}
		return fmt.Errorf("failed to create vector index: %w", err)
	}

	logrus.Info("DuckDB vector index created successfully")
	return nil
}
